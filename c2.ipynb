{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "import shortuuid\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from torchvision import models, transforms\n",
    "\n",
    "def ann_file(data_dir):\n",
    "    return os.path.join(data_dir, \"TrainAnnotations.csv\")\n",
    "\n",
    "\n",
    "TRAIN_DATA_DIR = \"data/TrainData-C2\"\n",
    "TRAIN_DATA_ANN_FILE = ann_file(TRAIN_DATA_DIR)\n",
    "\n",
    "TRAIN_SPLIT_DATA_DIR           = \"data/train/split\"\n",
    "TRAIN_SPLIT_ANN_FILE           = ann_file(TRAIN_SPLIT_DATA_DIR)\n",
    "TRAIN_SPLIT_AUGMENTED_DATA_DIR = \"data/train/augmented\"\n",
    "TRAIN_SPLIT_AUGMENTED_ANN_FILE = ann_file(TRAIN_SPLIT_AUGMENTED_DATA_DIR)\n",
    "TRAIN_SPLIT_PATCHES_DATA_DIR   = \"data/train/patches\"\n",
    "TRAIN_SPLIT_PATCHES_ANN_FILE   = ann_file(TRAIN_SPLIT_PATCHES_DATA_DIR)\n",
    "\n",
    "TRAIN_ALL_AUGMENTED_DATA_DIR   = \"data/train-all/augmented\"\n",
    "TRAIN_ALL_AUGMENTED_ANN_FILE   = ann_file(TRAIN_ALL_AUGMENTED_DATA_DIR)\n",
    "TRAIN_ALL_PATCHES_DATA_DIR     = \"data/train-all/patches\"\n",
    "TRAIN_ALL_PATCHES_ANN_FILE     = ann_file(TRAIN_ALL_PATCHES_DATA_DIR)\n",
    "\n",
    "VAL_SPLIT_DATA_DIR         = \"data/val/split\"\n",
    "VAL_SPLIT_ANN_FILE         = ann_file(VAL_SPLIT_DATA_DIR)\n",
    "VAL_SPLIT_PATCHES_DATA_DIR = \"data/val/patches\"\n",
    "VAL_SPLIT_PATCHES_ANN_FILE = ann_file(VAL_SPLIT_PATCHES_DATA_DIR)\n",
    "\n",
    "TEST_DATA_DIR         = \"data/TestData/\"\n",
    "TEST_PATCHES_DATA_DIR = \"data/test/patches\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Generate random, stratified 80/20 split for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directories for splits already exist. Skipping\n"
     ]
    }
   ],
   "source": [
    "if (os.path.exists(TRAIN_SPLIT_DATA_DIR) or os.path.exists(VAL_SPLIT_DATA_DIR)):\n",
    "    print(\"Data directories for splits already exist. Skipping\")\n",
    "else:\n",
    "    # Generate 80/20 split\n",
    "\n",
    "    print(\"Reading {} annotations...\".format(TRAIN_DATA_ANN_FILE))\n",
    "    ann_df = pd.read_csv(TRAIN_DATA_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "\n",
    "    print(\"Splitting data into training and validation sets...\")\n",
    "    train_df, val_df = train_test_split(ann_df,\n",
    "                                        train_size=0.80,\n",
    "                                        random_state=138,\n",
    "                                        shuffle=True,\n",
    "                                        stratify=ann_df[['annotation']].to_numpy(dtype=np.int32).flatten())\n",
    "\n",
    "    os.makedirs(TRAIN_SPLIT_DATA_DIR)\n",
    "    os.makedirs(VAL_SPLIT_DATA_DIR)\n",
    "    \n",
    "    print(\"Copying files for training split...\")\n",
    "    for _, row in train_df.iterrows():\n",
    "        filename = row['file_name']\n",
    "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
    "        dest = os.path.join(TRAIN_SPLIT_DATA_DIR, filename)\n",
    "        shutil.copyfile(src, dest)\n",
    "        \n",
    "    print(\"Generating training split annotations...\")\n",
    "    train_df.sort_values('file_name').to_csv(TRAIN_SPLIT_ANN_FILE, index=False)\n",
    "        \n",
    "    print(\"Copying files for validation split...\")\n",
    "    for _, row in val_df.iterrows():\n",
    "        filename = row['file_name']\n",
    "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
    "        dest = os.path.join(VAL_SPLIT_DATA_DIR, filename)\n",
    "        shutil.copyfile(src, dest)\n",
    "        \n",
    "    print(\"Generating validation split annotations...\")\n",
    "    val_df.sort_values('file_name').to_csv(VAL_SPLIT_ANN_FILE, index=False)\n",
    "        \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data\n",
    "Because the training dataset is unbalanced, augment the training data set by generating\n",
    "new images for the lower numbered samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DESIRED_CLASS_SAMPLE_COUNT = 400\n",
    "RANDOM_STATE = 13\n",
    "\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "PATCH_ROWS = 5\n",
    "PATCH_COLUMNS = 5\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.endswith(IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def augment_data(src_dir, src_ann_file, dest_dir, dest_ann_file, class_sample_count=500):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "    ann_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'}) \n",
    "    new_samples = {}\n",
    "    \n",
    "    for i in range(5):\n",
    "        class_df = ann_df.query(\"annotation == '{}'\".format(i))\n",
    "        num_class_samples = class_df.shape[0]\n",
    "        num_to_create = class_sample_count - num_class_samples\n",
    "            \n",
    "        print(\"Creating {} images for class {}\".format(num_to_create, i))\n",
    "        samples = class_df.sample(n=num_to_create, replace=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "        for idx, row in samples.iterrows():\n",
    "            new_filename = row['file_name'].split('.')[0] + \"_\" + shortuuid.uuid() + \".png\"\n",
    "    \n",
    "            # Apply transformations to each randomly selected sample\n",
    "            img = Image.open(src_dir + \"/\" + row['file_name'])\n",
    "            image_transforms = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=20, translate=(0.2, 0.2)),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                transforms.RandomResizedCrop((480, 640), scale=(1.0, 1.2)),\n",
    "            ])\n",
    "            transformed_img = image_transforms(img)\n",
    "            transformed_img.save(os.path.join(dest_dir, new_filename))\n",
    "    \n",
    "            new_samples[new_filename] = row['annotation']\n",
    "    \n",
    "    # Add to new dataframe\n",
    "    balanced_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    balanced_df = balanced_df.append(pd.DataFrame.from_records([(k, v) for k, v in new_samples.items()],\n",
    "                                                 columns=['file_name', 'annotation']))\n",
    "    \n",
    "    # Write new annotations\n",
    "    balanced_df.sort_values('file_name').to_csv(dest_ann_file, index=False)\n",
    "    \n",
    "    # Copy images from training data split\n",
    "    for file in glob.glob(src_dir + \"/*\"):\n",
    "        if is_image_file(file):\n",
    "            shutil.copy(file, os.path.join(dest_dir, os.path.basename(file)))\n",
    "\n",
    "\n",
    "def generate_image_patches(img, rows, cols):\n",
    "    \"\"\"\n",
    "    Generates a list of in-memory image overlapping patches\n",
    "    \n",
    "    Args:\n",
    "        rows - number of rows of patchs to cover the height of the image\n",
    "        cols - number of colums of patches to cover the width of the image\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    sizeX = img.shape[1]\n",
    "    sizeY = img.shape[0]\n",
    "    \n",
    "    patch_sizeX = 224\n",
    "    patch_sizeY = 224\n",
    "    patch_relative_centerX = 112\n",
    "    patch_relative_centerY = 112\n",
    "\n",
    "    for i in range(0,rows):\n",
    "        for j in range(0, cols):\n",
    "            center = (patch_relative_centerX + (sizeX - patch_sizeX)/(rows - 1)*i, \n",
    "                      patch_relative_centerY + (sizeY - patch_sizeY)/(cols - 1)*j)\n",
    "            patches.append(cv2.getRectSubPix(img, (patch_sizeX, patch_sizeY), center))\n",
    "            \n",
    "    return patches\n",
    "\n",
    "\n",
    "def generate_patch_files(in_dir, out_dir, rows, cols):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    images = [f for f in os.listdir(in_dir) if os.path.isfile(os.path.join(in_dir, f)) and is_image_file(f)]   \n",
    "    for im in images:\n",
    "        img = cv2.imread(os.path.join(in_dir, im))\n",
    "        patches = generate_image_patches(img, rows, cols)\n",
    "        \n",
    "        for i in range(0,rows):\n",
    "            for j in range(0, cols):\n",
    "                patch = patches[i*rows + j]\n",
    "                patch_name = im.split('.')[0] + '_' + str(i) + '_' + str(j) + '.png'\n",
    "                cv2.imwrite(out_dir + '/' + patch_name, patch)\n",
    "\n",
    "\n",
    "def generate_patch_annotations_df(df, rows, cols):\n",
    "    patches_ann = {}\n",
    "    \n",
    "    for ind in df.index: \n",
    "        file_name = df['file_name'][ind]\n",
    "        annotation = df['annotation'][ind]\n",
    "        \n",
    "        for i in range(0, rows):\n",
    "            for j in range(0, cols):\n",
    "                patch_name = file_name.split('.')[0] + '_' + str(i) + '_' + str(j) + '.png'\n",
    "                patches_ann[patch_name] = annotation\n",
    "    \n",
    "    return pd.DataFrame.from_records([(k, v) for k, v in patches_ann.items()], \n",
    "                                     columns=['file_name', 'annotation'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run data augmentation\n",
    "\n",
    "Perform the data augmentation on the training data set split to balance the class samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented SPLIT training data already exists. Skipping.\n",
      "Augmented ALL training data already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(TRAIN_SPLIT_AUGMENTED_DATA_DIR):\n",
    "    print(\"Augmented SPLIT training data already exists. Skipping.\")\n",
    "else:\n",
    "    print(\"Balancing class samples for SPLIT training data...\")\n",
    "    augment_data(TRAIN_SPLIT_DATA_DIR,\n",
    "                 TRAIN_SPLIT_ANN_FILE,\n",
    "                 TRAIN_SPLIT_AUGMENTED_DATA_DIR,\n",
    "                 TRAIN_SPLIT_AUGMENTED_ANN_FILE,\n",
    "                 class_sample_count=400)    \n",
    "    print(\"Done.\")\n",
    "\n",
    "if os.path.exists(TRAIN_ALL_AUGMENTED_DATA_DIR):\n",
    "    print(\"Augmented ALL training data already exists. Skipping.\")\n",
    "else:\n",
    "    print(\"Balancing class samples for ALL training data...\")\n",
    "    augment_data(TRAIN_DATA_DIR,\n",
    "                 TRAIN_DATA_ANN_FILE,\n",
    "                 TRAIN_ALL_AUGMENTED_DATA_DIR,\n",
    "                 TRAIN_ALL_AUGMENTED_ANN_FILE,\n",
    "                 class_sample_count=500)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/patches exists. Skipping.\n",
      "data/val/patches exists. Skipping.\n",
      "data/test/patches exists. Skipping.\n",
      "data/train-all/patches exists. Skipping.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# SPLIT train patches\n",
    "if os.path.exists(TRAIN_SPLIT_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TRAIN_SPLIT_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating SPLIT training data patches...\")\n",
    "    generate_patch_files(TRAIN_SPLIT_AUGMENTED_DATA_DIR, TRAIN_SPLIT_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating SPLIT training patch data annotations...\")\n",
    "    image_df = pd.read_csv(TRAIN_SPLIT_AUGMENTED_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(TRAIN_SPLIT_PATCHES_ANN_FILE, index=False)\n",
    "    \n",
    "# SPLIT val patches\n",
    "if os.path.exists(VAL_SPLIT_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(VAL_SPLIT_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating SPLIT validation data patches...\")\n",
    "    generate_patch_files(VAL_SPLIT_DATA_DIR, VAL_SPLIT_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating SPLIT validation patch data annotations...\")\n",
    "    image_df = pd.read_csv(VAL_SPLIT_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(VAL_SPLIT_PATCHES_ANN_FILE, index=False)\n",
    "\n",
    "# test patches\n",
    "if os.path.exists(TEST_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TEST_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating test data patches...\")\n",
    "    generate_patch_files(TEST_DATA_DIR, TEST_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    \n",
    "# ALL train patches\n",
    "if os.path.exists(TRAIN_ALL_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TRAIN_ALL_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating ALL train data patches...\")\n",
    "    generate_patch_files(TRAIN_ALL_AUGMENTED_DATA_DIR, TRAIN_ALL_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating ALL training patch data annotations...\")\n",
    "    image_df = pd.read_csv(TRAIN_ALL_AUGMENTED_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(TRAIN_ALL_PATCHES_ANN_FILE, index=False)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Datasets\n",
    "\n",
    "Given a directory of images and a CSV file of annotations, this defines a PyTorch Dataset which will load an image from disk and apply all configure transformations and return a tuple containing the image and label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SoybeanDataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, data_path, ann_df, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): path to images\n",
    "            ann_df (string): pandas data frame containing file names and annotations\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        self.data = ann_df\n",
    "        self.labels = np.asarray(self.data.iloc[:, 1])\n",
    "        \n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print('index:', index)\n",
    "        image_label = int(self.labels[index])\n",
    "        img_path = os.path.join(self.data_path, self.data.file_name[index])\n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Transform image\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "            \n",
    "        # Return image and the label\n",
    "        return img, image_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "\n",
    "class SoybeanTestDatasetFolder(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, data_path, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): path to images\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.images = []\n",
    "        \n",
    "        for root, _, fnames in sorted(os.walk(data_path, followlinks=True)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = fname\n",
    "                if is_image_file(path):\n",
    "                    self.images.append(path)\n",
    "\n",
    "                                       \n",
    "    def image_gen(self):\n",
    "        for i in self.images:\n",
    "            img_path = os.path.join(self.data_path, i)\n",
    "            img = Image.open(img_path)\n",
    "        \n",
    "            # Transform image\n",
    "            if self.transforms is not None:\n",
    "                img = self.transforms(img)\n",
    "                \n",
    "            yield img\n",
    "            \n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.image_gen())\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "\n",
    "class SoybeanDataGroup():\n",
    "    def __init__(self, class_weights, \n",
    "                 train_dataloader,\n",
    "                 val_dataloader=None,\n",
    "                 test_dataloader=None):\n",
    "        self.class_weights = class_weights\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "\n",
    "\n",
    "def compute_class_weights(df, y_col):\n",
    "    \"\"\"\n",
    "    Returns a list of class labels to 'balanced' weights based on the\n",
    "    frequency of the weights across the labels in the specified dataframe\n",
    "    \"\"\"\n",
    "    y = df[[y_col]].to_numpy(dtype=np.int32).flatten()\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "    return torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common image transformations\n",
    "These images transformations will apply to both train and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class SamplewiseCenterNormalize(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "        \"\"\"\n",
    "        \n",
    "        return torch.div(torch.add(tensor, torch.mul(torch.mean(tensor), -1)), torch.std(tensor) + 1e-6)\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "\n",
    "\n",
    "DATA_TRANSFORMS = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomAffine(degrees=20, translate=(0.2, 0.2)),\n",
    "    transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), shear=10, scale=(1.0, 1.2)),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    #transforms.RandomCrop(size=(480,640)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    # SamplewiseCenterNormalize()\n",
    "\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "TEST_DATA_TRANSFORMS = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    # SamplewiseCenterNormalize()\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 0.80/Val 0.20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train_val_split_group(class_weights=None):\n",
    "    \n",
    "    print(\"Reading annotations...\")\n",
    "    train_ann_df = pd.read_csv(TRAIN_SPLIT_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    val_ann_df   = pd.read_csv(VAL_SPLIT_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    \n",
    "    if class_weights is None:\n",
    "        print(\"Computing class weights...\")\n",
    "        class_weights = compute_class_weights(train_ann_df, 'annotation')\n",
    "        print(class_weights)\n",
    "    else:\n",
    "        print(\"Using class weights:\", class_weights)\n",
    "        \n",
    "    train_dataset = SoybeanDataset(TRAIN_SPLIT_PATCHES_DATA_DIR, train_ann_df, transforms=DATA_TRANSFORMS)\n",
    "    val_dataset = SoybeanDataset(VAL_SPLIT_PATCHES_DATA_DIR, val_ann_df, transforms=TEST_DATA_TRANSFORMS)\n",
    "    test_dataset  = SoybeanTestDatasetFolder(TEST_PATCHES_DATA_DIR, transforms=TEST_DATA_TRANSFORMS)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   pin_memory=True, \n",
    "                                                   num_workers=16)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 pin_memory=True,\n",
    "                                                 num_workers=16)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  pin_memory=True,\n",
    "                                                  num_workers=0)\n",
    "    \n",
    "    return SoybeanDataGroup(class_weights, train_dataloader, val_dataloader, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 100%\n",
    "\n",
    "Train with all the data in the `TrainData-C2` dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def all_train_data_group(class_weights=None):\n",
    "    print(\"Reading annotations...\")\n",
    "    ann_df = pd.read_csv(TRAIN_DATA_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    \n",
    "    if class_weights is None:\n",
    "        print(\"Computing class weights...\")\n",
    "        class_weights = compute_class_weights(ann_df, 'annotation')\n",
    "        print(class_weights)\n",
    "    else:\n",
    "        print(\"Using class weights:\", class_weights)\n",
    "\n",
    "    train_dataset = SoybeanDataset(TRAIN_DATA_PATCHES_DIR, ann_df, transforms=DATA_TRANSFORMS)\n",
    "    test_dataset  = SoybeanTestDatasetFolder(TEST_DATA_PATCHES_DIR, transforms=TEST_DATA_TRANSFORMS)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                   batch_size=BATCH_SIZE,\n",
    "                                                   pin_memory=True, \n",
    "                                                   num_workers=16)\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  pin_memory=True,\n",
    "                                                  num_workers=0)\n",
    "    \n",
    "    return SoybeanDataGroup(class_weights, train_dataloader, None, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This model is based on the VGG16 network with custom classifier layers \n",
    "with the feature layers initialized with weights based on the ImageNet data. \n",
    "\n",
    "The number of neurons and dropout rates in the classifier layers are parameterized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_model(n1, n2, dropout, batch_normalization=False):\n",
    "    if batch_normalization:\n",
    "        model = models.vgg16_bn(pretrained=True)\n",
    "    else:\n",
    "        model = models.vgg16(pretrained=True) \n",
    "\n",
    "    # Freeze training for all layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "    \n",
    "    # Replace the VGG16 classifier with a custom classifier for soybean wilting \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(512 * 1 * 1, n1, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(n1, n2, bias=True),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=dropout),\n",
    "        nn.Linear(n2, 5, bias=True)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "For training and validation, this trains a model across a configured number of epochs and outputs the training and validation loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=25):\n",
    "    \"\"\"\n",
    "    Trains the specified neural network model\n",
    "    \n",
    "    Args:\n",
    "        model:         - neural network model to train\n",
    "        criterion:     - loss function\n",
    "        optimizer:     - gradient descent optimization algorithm\n",
    "        dataloaders:   - dict of DataLoaders for training and validation data\n",
    "        num_epochs:    - number of epochs to train model\n",
    "    Returns:\n",
    "        model   - trained model with weights from the epoch with the best validation accuracy\n",
    "        history - dict of training and validation loss and accuracy for all epochs\n",
    "    \"\"\"\n",
    "    since = time.time()\n",
    "    \n",
    "    # summary(model, input_size=(3, 224, 224))\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    history = {'train': {'loss': [], 'acc': []}}\n",
    "    phases = ['train']\n",
    "    if ('val' in dataloaders and dataloaders['val'] is not None):\n",
    "        phases += ['val']\n",
    "        history['val'] = {'loss': [], 'acc': []}\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and optionally, a validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                \n",
    "            phase_start = time.time()\n",
    "\n",
    "            sample_count = 0\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:               \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "                        nn.utils.clip_grad_value_(model.parameters(), 0.5)\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                sample_count += inputs.size(0)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += preds.eq(labels.data.view_as(preds)).cpu().sum()\n",
    "            \n",
    "            print('Num samples', sample_count)\n",
    "            \n",
    "            epoch_loss = running_loss / sample_count\n",
    "            epoch_acc = running_corrects.double() / sample_count\n",
    "            \n",
    "            history[phase]['loss'].append(epoch_loss)\n",
    "            history[phase]['acc'].append(epoch_acc)\n",
    "            \n",
    "            phase_end = time.time()\n",
    "            phase_elapsed = phase_end - phase_start\n",
    "\n",
    "            print('{} {} loss: {:.4f} accuracy: {:.4f}'.format(\n",
    "                phase, str(timedelta(seconds=phase_elapsed)), epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if ('val' not in phases or phase == 'val') and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        epoch_elapsed = epoch_end - epoch_start\n",
    "        print('Elapsed time: {}'.format(str(timedelta(seconds=epoch_elapsed))))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_sample_count(dataset, sampler):\n",
    "    if (sampler is not None):\n",
    "        return len(sampler)\n",
    "    elif (dataset is not None):\n",
    "        return len(dataset)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def train(model, group, num_epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss(weight=group.class_weights)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-07)\n",
    "    \n",
    "    dataloaders = {\n",
    "        'train': group.train_dataloader,\n",
    "        'val': group.val_dataloader\n",
    "    }\n",
    " \n",
    "    model_trained, history = train_model(model, criterion, optimizer, dataloaders, num_epochs)\n",
    "    \n",
    "    \n",
    "    return model_trained, history\n",
    "\n",
    "\n",
    "def get_all_labels(loader):\n",
    "    all_labels = torch.tensor([], dtype=torch.long)\n",
    "    for batch in loader:\n",
    "        _, labels = batch\n",
    "        all_labels = torch.cat((all_labels, labels), dim=0)\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "def get_all_whole_image_labels(patch_labels):\n",
    "    patch_label_groups = np.split(patch_labels, int(len(patch_labels)/(PATCH_ROWS * PATCH_COLUMNS)))\n",
    "    image_labels = np.array(list(map(lambda x: x[0], patch_label_groups)))\n",
    "    return image_labels\n",
    "\n",
    "\n",
    "def get_all_whole_image_predictions(patch_preds):\n",
    "    patch_pred_groups = np.split(patch_preds, int(len(patch_preds)/(PATCH_ROWS * PATCH_COLUMNS)))\n",
    "    image_preds = np.array(list(map(lambda x: stats.mode(x).mode[0], patch_pred_groups)))\n",
    "    return image_preds\n",
    "\n",
    "\n",
    "def plot_metrics(model, history, train_dataloader, val_dataloader=None):\n",
    "    \n",
    "    print()\n",
    "    print('Metrics')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(history['train']['loss']) + 1)\n",
    "\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, history['train']['loss'], 'g-')\n",
    "    loss_legend = ['Training Loss']\n",
    "    \n",
    "    if ('val' in history and history['val'] is not None):\n",
    "        plt.plot(epoch_count, history['val']['loss'], 'b-')\n",
    "        loss_legend += ['Validation Loss']\n",
    "        \n",
    "    plt.legend(loss_legend)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize accuracy history\n",
    "    plt.plot(epoch_count, history['train']['acc'], 'g-')\n",
    "    acc_legend = ['Training Accuracy']\n",
    "    \n",
    "    if ('val' in history and history['val'] is not None):\n",
    "        plt.plot(epoch_count, history['val']['acc'], 'b-')\n",
    "        acc_legend += ['Validation Accuracy']\n",
    "    \n",
    "    plt.legend(acc_legend)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    # Training confusion matrix\n",
    "    train_patch_labels = get_all_labels(train_dataloader).cpu().numpy()\n",
    "    train_patch_predictions = predict(model, train_dataloader).cpu().numpy()\n",
    "    \n",
    "    print(\"Training Confusion Matrix of Patches\")\n",
    "    print(\"-\" * 30)\n",
    "    print_confusion_matrix(train_patch_labels, train_patch_predictions)\n",
    "    \n",
    "    print(\"Training Confusion Matrix of Whole Images\")\n",
    "    print(\"-\" * 30)\n",
    "    print_confusion_matrix(get_all_whole_image_labels(train_patch_labels),\n",
    "                           get_all_whole_image_predictions(train_patch_predictions))\n",
    "    \n",
    "    # Validation confusion matrix\n",
    "    if val_dataloader is not None:\n",
    "        val_patch_labels = get_all_labels(val_dataloader).cpu().numpy()\n",
    "        val_patch_predictions = predict(model, val_dataloader).cpu().numpy()\n",
    "        \n",
    "        print(\"Validation Confusion Matrix of Patches\")\n",
    "        print(\"-\" * 30)\n",
    "        print_confusion_matrix(val_patch_labels, val_patch_predictions)\n",
    "        \n",
    "        print(\"Validation Confusion Matrix of Whole Images\")\n",
    "        print(\"-\" * 30)\n",
    "        print_confusion_matrix(get_all_whole_image_labels(val_patch_labels),\n",
    "                               get_all_whole_image_predictions(val_patch_predictions))\n",
    "\n",
    "\n",
    "def train_and_test(model, group, num_epochs=60):\n",
    "    model_trained, history = train(model, group, num_epochs)\n",
    "    \n",
    "    # Plot history metrics\n",
    "    plot_metrics(model_trained, history, group.train_dataloader, group.val_dataloader)\n",
    "    \n",
    "    # Classify test data\n",
    "    return predict(model_trained, group.test_dataloader)\n",
    "\n",
    "\n",
    "def predict(model, dataloader):\n",
    "    predictions = torch.tensor([], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            if (type(data) is list):\n",
    "                images = data[0].to(device)\n",
    "            else:\n",
    "                images = data.to(device)\n",
    "            model.eval()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions = torch.cat((predictions, predicted))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def predict_whole_images(patch_predictions, rows, columns, csvfile):\n",
    "    y_hat_test = patch_predictions.cpu().numpy()\n",
    "    y_hat_patch_groups = np.split(y_hat_test, int(len(y_hat_test)/(rows * columns)))\n",
    "    y_hat_whole_images = list(map(lambda x: stats.mode(x).mode[0], y_hat_patch_groups))\n",
    "\n",
    "    for k, v in sorted(Counter(y_hat_whole_images).items()): \n",
    "        print(str(k) + ': '+ str(v))    \n",
    "\n",
    "    one_hots = [np.zeros((5,1)) for pred in y_hat_whole_images]\n",
    "    for i in range(len(one_hots)):\n",
    "        pred = y_hat_whole_images[i]  # the index of the one-hot encoding\n",
    "        one_hots[i][pred] = 1\n",
    "    with open(csvfile, 'w') as predictions_file:\n",
    "        writer = csv.writer(predictions_file)\n",
    "        for pred in one_hots:\n",
    "            pred = np.array(pred, dtype=int)\n",
    "            writer.writerow(pred.T.tolist()[0])\n",
    "    print('Finished generating predictions to', csvfile)\n",
    "\n",
    "\n",
    "def print_confusion_matrix(y, y_hat):\n",
    "    confusion_matrix = np.zeros((5, 5))\n",
    "    labels = [0, 1, 2, 3, 4]\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            ground_truth = y==labels[i]\n",
    "            prediction = y_hat==labels[j]\n",
    "            confusion_matrix[i, j] = sum(np.bitwise_and(ground_truth, prediction))\n",
    "    df = pd.DataFrame(confusion_matrix, dtype=int)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test - 80/20 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.5).to(device)\n",
    "y_hat_test = train_and_test(model, train_val_split_group(), num_epochs=1)\n",
    "predictions_file = \"predict_c2_g1_\" + shortuuid.uuid()\n",
    "print('predictions file:', predictions_file)\n",
    "predict_whole_images(y_hat_test, 5, 5, predictions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test - All Train Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.1).to(device)\n",
    "y_hat_test = train_and_test(model, group_3())\n",
    "predict_whole_images(y_hat_test, 5, 5, 'predictions_c2_g3.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "The following hyperparameters can be tuned:\n",
    "1. `n1` - Number of neurons in the first classifier dense layer\n",
    "2. `n2` - Number of neurons in the second classifier dense layer\n",
    "3. `d` - Dropout rate after classifier dense layers\n",
    "4. class weights - `[1,1,1,1,1]` (default) or `[1,1,5,5,1]`\n",
    "5. batch normalization - `no` or `yes`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(name, model, class_weights=None, num_epochs=60):\n",
    "    y_hat_test = train_and_test(model, train_val_split_group(class_weights), num_epochs)\n",
    "    predictions_file = \"predict_c2_{}_{}.csv\".format(name, shortuuid.uuid())\n",
    "    print('predictions file:', predictions_file)\n",
    "    predict_whole_images(y_hat_test, PATCH_ROWS, PATCH_COLUMNS, predictions_file)\n",
    "    return y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H1: 1024-128-5\n",
    "\n",
    "* DNN Structure: 1024-128-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading annotations...\n",
      "Computing class weights...\n",
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "Epoch 0/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.073406 loss: 1.3310 accuracy: 0.4846\n",
      "Num samples 6375\n",
      "val 0:00:11.875673 loss: 9.5041 accuracy: 0.3812\n",
      "Elapsed time: 0:01:42.951981\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.344711 loss: 1.2085 accuracy: 0.5304\n",
      "Num samples 6375\n",
      "val 0:00:11.946585 loss: 9.0814 accuracy: 0.3853\n",
      "Elapsed time: 0:01:43.293341\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.705893 loss: 1.1496 accuracy: 0.5561\n",
      "Num samples 6375\n",
      "val 0:00:11.943962 loss: 6.9452 accuracy: 0.3914\n",
      "Elapsed time: 0:01:43.652851\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.741663 loss: 1.1211 accuracy: 0.5760\n",
      "Num samples 6375\n",
      "val 0:00:11.948731 loss: 7.4843 accuracy: 0.3933\n",
      "Elapsed time: 0:01:43.693568\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.999556 loss: 1.0872 accuracy: 0.5864\n",
      "Num samples 6375\n",
      "val 0:00:12.013493 loss: 7.7102 accuracy: 0.3947\n",
      "Elapsed time: 0:01:44.016086\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.808032 loss: 1.0687 accuracy: 0.5981\n",
      "Num samples 6375\n",
      "val 0:00:12.114915 loss: 6.1691 accuracy: 0.3895\n",
      "Elapsed time: 0:01:43.923638\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.034882 loss: 1.0549 accuracy: 0.6021\n",
      "Num samples 6375\n",
      "val 0:00:11.970834 loss: 6.8224 accuracy: 0.3947\n",
      "Elapsed time: 0:01:44.006553\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.216580 loss: 1.0398 accuracy: 0.6070\n",
      "Num samples 6375\n",
      "val 0:00:12.214634 loss: 5.9783 accuracy: 0.3934\n",
      "Elapsed time: 0:01:45.432236\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.508143 loss: 1.0335 accuracy: 0.6133\n",
      "Num samples 6375\n",
      "val 0:00:12.154927 loss: 6.6595 accuracy: 0.3948\n",
      "Elapsed time: 0:01:45.666227\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.253750 loss: 1.0249 accuracy: 0.6204\n",
      "Num samples 6375\n",
      "val 0:00:12.116843 loss: 6.4347 accuracy: 0.3940\n",
      "Elapsed time: 0:01:47.371438\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.571317 loss: 1.0292 accuracy: 0.6222\n",
      "Num samples 6375\n",
      "val 0:00:12.174321 loss: 6.4006 accuracy: 0.3962\n",
      "Elapsed time: 0:01:44.748773\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.363774 loss: 1.0117 accuracy: 0.6221\n",
      "Num samples 6375\n",
      "val 0:00:11.967515 loss: 5.6783 accuracy: 0.3944\n",
      "Elapsed time: 0:01:45.332146\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.747933 loss: 0.9993 accuracy: 0.6280\n",
      "Num samples 6375\n",
      "val 0:00:11.976996 loss: 5.9718 accuracy: 0.3951\n",
      "Elapsed time: 0:01:43.725852\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.920419 loss: 1.0100 accuracy: 0.6238\n",
      "Num samples 6375\n",
      "val 0:00:12.101327 loss: 6.5306 accuracy: 0.3955\n",
      "Elapsed time: 0:01:44.022495\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.991248 loss: 1.0002 accuracy: 0.6289\n",
      "Num samples 6375\n",
      "val 0:00:12.093505 loss: 5.4305 accuracy: 0.3975\n",
      "Elapsed time: 0:01:44.087939\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.134621 loss: 0.9904 accuracy: 0.6314\n",
      "Num samples 6375\n",
      "val 0:00:12.044888 loss: 5.8371 accuracy: 0.3989\n",
      "Elapsed time: 0:01:44.182581\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.077731 loss: 0.9896 accuracy: 0.6301\n",
      "Num samples 6375\n",
      "val 0:00:12.063294 loss: 5.7345 accuracy: 0.3964\n",
      "Elapsed time: 0:01:44.141735\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.397856 loss: 0.9897 accuracy: 0.6352\n",
      "Num samples 6375\n",
      "val 0:00:12.142217 loss: 5.3153 accuracy: 0.3987\n",
      "Elapsed time: 0:01:44.540769\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.242291 loss: 0.9836 accuracy: 0.6360\n",
      "Num samples 6375\n",
      "val 0:00:12.072427 loss: 5.7073 accuracy: 0.3953\n",
      "Elapsed time: 0:01:44.315574\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.984546 loss: 0.9925 accuracy: 0.6364\n",
      "Num samples 6375\n",
      "val 0:00:12.071807 loss: 4.8547 accuracy: 0.3965\n",
      "Elapsed time: 0:01:44.057069\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.862512 loss: 0.9795 accuracy: 0.6405\n",
      "Num samples 6375\n",
      "val 0:00:12.020434 loss: 4.8673 accuracy: 0.4002\n",
      "Elapsed time: 0:01:43.886206\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.773773 loss: 0.9658 accuracy: 0.6416\n",
      "Num samples 6375\n",
      "val 0:00:12.234503 loss: 5.2517 accuracy: 0.3950\n",
      "Elapsed time: 0:01:44.009056\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.476558 loss: 0.9622 accuracy: 0.6434\n",
      "Num samples 6375\n",
      "val 0:00:12.121759 loss: 4.6771 accuracy: 0.4028\n",
      "Elapsed time: 0:01:44.601445\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.288147 loss: 0.9722 accuracy: 0.6429\n",
      "Num samples 6375\n",
      "val 0:00:12.422063 loss: 5.4259 accuracy: 0.4003\n",
      "Elapsed time: 0:01:45.711070\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.564033 loss: 0.9740 accuracy: 0.6462\n",
      "Num samples 6375\n",
      "val 0:00:12.309836 loss: 4.8959 accuracy: 0.4013\n",
      "Elapsed time: 0:01:45.874759\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.793069 loss: 0.9733 accuracy: 0.6446\n",
      "Num samples 6375\n",
      "val 0:00:12.018280 loss: 5.1549 accuracy: 0.4005\n",
      "Elapsed time: 0:01:44.812231\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.850796 loss: 0.9659 accuracy: 0.6401\n",
      "Num samples 6375\n",
      "val 0:00:12.654630 loss: 4.9226 accuracy: 0.4039\n",
      "Elapsed time: 0:01:47.508662\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.237078 loss: 0.9662 accuracy: 0.6444\n",
      "Num samples 6375\n",
      "val 0:00:12.456485 loss: 4.7994 accuracy: 0.4045\n",
      "Elapsed time: 0:01:45.696593\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.743463 loss: 0.9658 accuracy: 0.6455\n",
      "Num samples 6375\n",
      "val 0:00:12.123474 loss: 4.8305 accuracy: 0.4025\n",
      "Elapsed time: 0:01:44.867861\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.077026 loss: 0.9597 accuracy: 0.6510\n",
      "Num samples 6375\n",
      "val 0:00:11.960951 loss: 4.7682 accuracy: 0.4011\n",
      "Elapsed time: 0:01:45.038800\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.426943 loss: 0.9657 accuracy: 0.6485\n",
      "Num samples 6375\n",
      "val 0:00:12.074834 loss: 4.5455 accuracy: 0.4075\n",
      "Elapsed time: 0:01:45.504804\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.502509 loss: 0.9729 accuracy: 0.6486\n",
      "Num samples 6375\n",
      "val 0:00:12.096422 loss: 5.0464 accuracy: 0.4024\n",
      "Elapsed time: 0:01:44.599649\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.851103 loss: 0.9556 accuracy: 0.6513\n",
      "Num samples 6375\n",
      "val 0:00:12.603651 loss: 4.7266 accuracy: 0.4047\n",
      "Elapsed time: 0:01:45.455606\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.372455 loss: 0.9429 accuracy: 0.6519\n",
      "Num samples 6375\n",
      "val 0:00:12.234303 loss: 4.0504 accuracy: 0.4135\n",
      "Elapsed time: 0:01:47.609981\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.522867 loss: 0.9477 accuracy: 0.6537\n",
      "Num samples 6375\n",
      "val 0:00:12.751604 loss: 4.7078 accuracy: 0.4075\n",
      "Elapsed time: 0:01:46.275217\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.282451 loss: 0.9521 accuracy: 0.6525\n",
      "Num samples 6375\n",
      "val 0:00:12.560227 loss: 4.3144 accuracy: 0.4045\n",
      "Elapsed time: 0:01:48.843539\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.376387 loss: 0.9608 accuracy: 0.6514\n",
      "Num samples 6375\n",
      "val 0:00:12.620126 loss: 4.8991 accuracy: 0.4008\n",
      "Elapsed time: 0:01:48.997322\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.598639 loss: 0.9579 accuracy: 0.6495\n",
      "Num samples 6375\n",
      "val 0:00:12.869933 loss: 3.9016 accuracy: 0.4082\n",
      "Elapsed time: 0:01:49.469491\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.466047 loss: 0.9484 accuracy: 0.6524\n",
      "Num samples 6375\n",
      "val 0:00:12.632668 loss: 3.6643 accuracy: 0.4063\n",
      "Elapsed time: 0:01:49.099572\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.527528 loss: 0.9394 accuracy: 0.6503\n",
      "Num samples 6375\n",
      "val 0:00:12.376686 loss: 4.2652 accuracy: 0.4047\n",
      "Elapsed time: 0:01:47.905149\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.485315 loss: 0.9472 accuracy: 0.6574\n",
      "Num samples 6375\n",
      "val 0:00:12.628148 loss: 4.3621 accuracy: 0.4056\n",
      "Elapsed time: 0:01:49.114298\n",
      "\n",
      "Epoch 41/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.041926 loss: 0.9409 accuracy: 0.6572\n",
      "Num samples 6375\n",
      "val 0:00:11.982982 loss: 4.5254 accuracy: 0.4107\n",
      "Elapsed time: 0:01:46.025716\n",
      "\n",
      "Epoch 42/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.194332 loss: 0.9518 accuracy: 0.6549\n",
      "Num samples 6375\n",
      "val 0:00:12.932553 loss: 4.6073 accuracy: 0.4077\n",
      "Elapsed time: 0:01:48.127664\n",
      "\n",
      "Epoch 43/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples 50000\n",
      "train 0:01:36.636716 loss: 0.9325 accuracy: 0.6565\n",
      "Num samples 6375\n",
      "val 0:00:12.769505 loss: 4.0996 accuracy: 0.4050\n",
      "Elapsed time: 0:01:49.407048\n",
      "\n",
      "Epoch 44/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.911863 loss: 0.9394 accuracy: 0.6581\n",
      "Num samples 6375\n",
      "val 0:00:12.681767 loss: 4.1986 accuracy: 0.4207\n",
      "Elapsed time: 0:01:47.596984\n",
      "\n",
      "Epoch 45/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.778549 loss: 0.9466 accuracy: 0.6568\n",
      "Num samples 6375\n",
      "val 0:00:12.659348 loss: 4.2770 accuracy: 0.4042\n",
      "Elapsed time: 0:01:49.438734\n",
      "\n",
      "Epoch 46/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.529323 loss: 0.9278 accuracy: 0.6610\n",
      "Num samples 6375\n",
      "val 0:00:12.647430 loss: 3.9769 accuracy: 0.4193\n",
      "Elapsed time: 0:01:49.177633\n",
      "\n",
      "Epoch 47/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.417172 loss: 0.9397 accuracy: 0.6551\n",
      "Num samples 6375\n",
      "val 0:00:12.472143 loss: 3.9572 accuracy: 0.4107\n",
      "Elapsed time: 0:01:45.890189\n",
      "\n",
      "Epoch 48/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.468306 loss: 0.9305 accuracy: 0.6601\n",
      "Num samples 6375\n",
      "val 0:00:12.569286 loss: 3.8204 accuracy: 0.4105\n",
      "Elapsed time: 0:01:49.038453\n",
      "\n",
      "Epoch 49/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.168231 loss: 0.9358 accuracy: 0.6562\n",
      "Num samples 6375\n",
      "val 0:00:12.779844 loss: 4.0248 accuracy: 0.4162\n",
      "Elapsed time: 0:01:48.948787\n",
      "\n",
      "Epoch 50/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.647866 loss: 0.9301 accuracy: 0.6597\n",
      "Num samples 6375\n",
      "val 0:00:12.645137 loss: 3.4841 accuracy: 0.4088\n",
      "Elapsed time: 0:01:48.293839\n",
      "\n",
      "Epoch 51/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.452280 loss: 0.9364 accuracy: 0.6575\n",
      "Num samples 6375\n",
      "val 0:00:12.697688 loss: 4.3070 accuracy: 0.4055\n",
      "Elapsed time: 0:01:48.150842\n",
      "\n",
      "Epoch 52/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:37.821438 loss: 0.9347 accuracy: 0.6603\n",
      "Num samples 6375\n",
      "val 0:00:12.396683 loss: 3.8137 accuracy: 0.4089\n",
      "Elapsed time: 0:01:50.218926\n",
      "\n",
      "Epoch 53/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.528016 loss: 0.9189 accuracy: 0.6623\n",
      "Num samples 6375\n",
      "val 0:00:12.560073 loss: 4.0609 accuracy: 0.4198\n",
      "Elapsed time: 0:01:48.089087\n",
      "\n",
      "Epoch 54/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.594115 loss: 0.9296 accuracy: 0.6609\n",
      "Num samples 6375\n",
      "val 0:00:12.532070 loss: 3.6046 accuracy: 0.4078\n",
      "Elapsed time: 0:01:48.127192\n",
      "\n",
      "Epoch 55/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.753296 loss: 0.9315 accuracy: 0.6586\n",
      "Num samples 6375\n",
      "val 0:00:12.639668 loss: 3.7971 accuracy: 0.4146\n",
      "Elapsed time: 0:01:48.393873\n",
      "\n",
      "Epoch 56/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.715412 loss: 0.9322 accuracy: 0.6611\n",
      "Num samples 6375\n",
      "val 0:00:12.602057 loss: 3.6757 accuracy: 0.4075\n",
      "Elapsed time: 0:01:48.318354\n",
      "\n",
      "Epoch 57/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.923866 loss: 0.9343 accuracy: 0.6625\n",
      "Num samples 6375\n",
      "val 0:00:12.600528 loss: 4.2323 accuracy: 0.4055\n",
      "Elapsed time: 0:01:48.525272\n",
      "\n",
      "Epoch 58/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.588286 loss: 0.9245 accuracy: 0.6631\n",
      "Num samples 6375\n",
      "val 0:00:12.584370 loss: 3.7578 accuracy: 0.4141\n",
      "Elapsed time: 0:01:48.173758\n",
      "\n",
      "Epoch 59/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.557238 loss: 0.9201 accuracy: 0.6623\n",
      "Num samples 6375\n",
      "val 0:00:12.570675 loss: 3.7044 accuracy: 0.4204\n",
      "Elapsed time: 0:01:48.128613\n",
      "\n",
      "Training complete in 106m 20s\n",
      "Best acc: 0.420706\n",
      "\n",
      "Metrics\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix of Patches\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>9926</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9761</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9010</td>\n",
       "      <td>57</td>\n",
       "      <td>87</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6153</td>\n",
       "      <td>3</td>\n",
       "      <td>444</td>\n",
       "      <td>3397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>728</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1   2    3     4\n",
       "0  20  9926   4   14    36\n",
       "1   1  9761   1   16   221\n",
       "2   3  9010  57   87   843\n",
       "3   3  6153   3  444  3397\n",
       "4   0   728   1   21  9250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix of Whole Images\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.bool_' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3bca6f2d990f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-68cb2501d750>\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(name, model, class_weights, num_epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_val_split_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpredictions_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"predict_c2_{}_{}.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortuuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predictions file:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredict_whole_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_ROWS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATCH_COLUMNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7bbf80cbf694>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(model, group, num_epochs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# Plot history metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Classify test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7bbf80cbf694>\u001b[0m in \u001b[0;36mplot_metrics\u001b[0;34m(model, history, train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     print_confusion_matrix(get_all_whole_image_labels(train_patch_labels),\n\u001b[0;32m---> 93\u001b[0;31m                            get_all_whole_image_predictions(train_patch_predictions))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Validation confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-7bbf80cbf694>\u001b[0m in \u001b[0;36mprint_confusion_matrix\u001b[0;34m(y, y_hat)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.bool_' object is not iterable"
     ]
    }
   ],
   "source": [
    "model = get_model(1024, 128, 0.5).to(device)\n",
    "run_trial(\"h1\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading annotations...\n",
      "Computing class weights...\n",
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "Training Confusion Matrix of Whole Images\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1  2  3    4\n",
       "0  0  400  0  0    0\n",
       "1  0  400  0  0    0\n",
       "2  0  381  2  0   17\n",
       "3  0  294  0  0  106\n",
       "4  0    9  0  0  391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix of Patches\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>2431</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1630</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1  2    3    4\n",
       "0  13  2431  0    3    3\n",
       "1   2  1630  1    3   14\n",
       "2   5   564  0   37   44\n",
       "3  27   300  0  119  204\n",
       "4   1    41  0   13  920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix of Whole Images\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2  3   4\n",
       "0  0  98  0  0   0\n",
       "1  0  66  0  0   0\n",
       "2  0  24  0  1   1\n",
       "3  0  14  0  4   8\n",
       "4  0   0  0  0  39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = train_val_split_group()\n",
    "train_dataloader = group.train_dataloader\n",
    "val_dataloader = group.val_dataloader\n",
    "\n",
    "# Training confusion matrix\n",
    "train_patch_labels = get_all_labels(train_dataloader).cpu().numpy()\n",
    "train_patch_predictions = predict(model, train_dataloader).cpu().numpy()\n",
    "\n",
    "#print(\"Training Confusion Matrix of Patches\")\n",
    "#print(\"-\" * 30)\n",
    "#print_confusion_matrix(train_patch_labels, train_patch_predictions)\n",
    "\n",
    "print(\"Training Confusion Matrix of Whole Images\")\n",
    "print(\"-\" * 30)\n",
    "print_confusion_matrix(get_all_whole_image_labels(train_patch_labels),\n",
    "                       get_all_whole_image_predictions(train_patch_predictions))\n",
    "\n",
    "# Validation confusion matrix\n",
    "if val_dataloader is not None:\n",
    "    val_patch_labels = get_all_labels(val_dataloader).cpu().numpy()\n",
    "    val_patch_predictions = predict(model, val_dataloader).cpu().numpy()\n",
    "\n",
    "    print(\"Validation Confusion Matrix of Patches\")\n",
    "    print(\"-\" * 30)\n",
    "    print_confusion_matrix(val_patch_labels, val_patch_predictions)\n",
    "\n",
    "    print(\"Validation Confusion Matrix of Whole Images\")\n",
    "    print(\"-\" * 30)\n",
    "    print_confusion_matrix(get_all_whole_image_labels(val_patch_labels),\n",
    "                           get_all_whole_image_predictions(val_patch_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H2: 2048-256-5\n",
    "\n",
    "* DNN Structure: 2048-256-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading annotations...\n",
      "Computing class weights...\n",
      "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
      "Epoch 0/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.446317 loss: 1.3905 accuracy: 0.4789\n",
      "Num samples 6375\n",
      "val 0:00:12.701587 loss: 9.2033 accuracy: 0.3824\n",
      "Elapsed time: 0:01:46.150866\n",
      "\n",
      "Epoch 1/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.409611 loss: 1.2681 accuracy: 0.5193\n",
      "Num samples 6375\n",
      "val 0:00:12.719525 loss: 8.2036 accuracy: 0.3848\n",
      "Elapsed time: 0:01:49.132174\n",
      "\n",
      "Epoch 2/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.383533 loss: 1.1811 accuracy: 0.5454\n",
      "Num samples 6375\n",
      "val 0:00:12.390535 loss: 9.0899 accuracy: 0.3915\n",
      "Elapsed time: 0:01:47.777464\n",
      "\n",
      "Epoch 3/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.742720 loss: 1.1304 accuracy: 0.5666\n",
      "Num samples 6375\n",
      "val 0:00:12.707570 loss: 8.9100 accuracy: 0.3962\n",
      "Elapsed time: 0:01:47.453331\n",
      "\n",
      "Epoch 4/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.798719 loss: 1.1193 accuracy: 0.5775\n",
      "Num samples 6375\n",
      "val 0:00:12.342146 loss: 8.5697 accuracy: 0.3942\n",
      "Elapsed time: 0:01:47.141854\n",
      "\n",
      "Epoch 5/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.846532 loss: 1.1040 accuracy: 0.5884\n",
      "Num samples 6375\n",
      "val 0:00:12.117848 loss: 8.1710 accuracy: 0.3909\n",
      "Elapsed time: 0:01:44.965247\n",
      "\n",
      "Epoch 6/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.870075 loss: 1.0611 accuracy: 0.6009\n",
      "Num samples 6375\n",
      "val 0:00:12.059290 loss: 7.0186 accuracy: 0.3962\n",
      "Elapsed time: 0:01:45.930078\n",
      "\n",
      "Epoch 7/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.317368 loss: 1.0619 accuracy: 0.6049\n",
      "Num samples 6375\n",
      "val 0:00:12.378101 loss: 6.9861 accuracy: 0.3933\n",
      "Elapsed time: 0:01:47.696587\n",
      "\n",
      "Epoch 8/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.770303 loss: 1.0465 accuracy: 0.6130\n",
      "Num samples 6375\n",
      "val 0:00:12.031612 loss: 7.5295 accuracy: 0.3947\n",
      "Elapsed time: 0:01:44.802763\n",
      "\n",
      "Epoch 9/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.368777 loss: 1.0386 accuracy: 0.6172\n",
      "Num samples 6375\n",
      "val 0:00:12.865901 loss: 7.6036 accuracy: 0.3958\n",
      "Elapsed time: 0:01:46.235446\n",
      "\n",
      "Epoch 10/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.609665 loss: 1.0223 accuracy: 0.6228\n",
      "Num samples 6375\n",
      "val 0:00:12.547639 loss: 7.0384 accuracy: 0.3936\n",
      "Elapsed time: 0:01:47.158131\n",
      "\n",
      "Epoch 11/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.925797 loss: 1.0205 accuracy: 0.6236\n",
      "Num samples 6375\n",
      "val 0:00:12.139263 loss: 6.1884 accuracy: 0.3940\n",
      "Elapsed time: 0:01:46.065908\n",
      "\n",
      "Epoch 12/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.408318 loss: 0.9992 accuracy: 0.6279\n",
      "Num samples 6375\n",
      "val 0:00:12.110076 loss: 6.7486 accuracy: 0.3944\n",
      "Elapsed time: 0:01:45.519231\n",
      "\n",
      "Epoch 13/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.145896 loss: 1.0120 accuracy: 0.6296\n",
      "Num samples 6375\n",
      "val 0:00:12.138463 loss: 4.9034 accuracy: 0.3995\n",
      "Elapsed time: 0:01:46.287674\n",
      "\n",
      "Epoch 14/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.735940 loss: 0.9926 accuracy: 0.6278\n",
      "Num samples 6375\n",
      "val 0:00:12.586497 loss: 6.1110 accuracy: 0.3986\n",
      "Elapsed time: 0:01:47.323260\n",
      "\n",
      "Epoch 15/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.195469 loss: 1.0007 accuracy: 0.6359\n",
      "Num samples 6375\n",
      "val 0:00:12.079826 loss: 5.8901 accuracy: 0.3944\n",
      "Elapsed time: 0:01:48.276203\n",
      "\n",
      "Epoch 16/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.949790 loss: 0.9878 accuracy: 0.6347\n",
      "Num samples 6375\n",
      "val 0:00:12.632655 loss: 5.2959 accuracy: 0.3995\n",
      "Elapsed time: 0:01:47.583317\n",
      "\n",
      "Epoch 17/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:37.341331 loss: 0.9828 accuracy: 0.6378\n",
      "Num samples 6375\n",
      "val 0:00:12.922867 loss: 4.7530 accuracy: 0.4083\n",
      "Elapsed time: 0:01:50.267232\n",
      "\n",
      "Epoch 18/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.369819 loss: 0.9807 accuracy: 0.6355\n",
      "Num samples 6375\n",
      "val 0:00:12.278671 loss: 5.1359 accuracy: 0.4030\n",
      "Elapsed time: 0:01:47.649202\n",
      "\n",
      "Epoch 19/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.316848 loss: 0.9868 accuracy: 0.6389\n",
      "Num samples 6375\n",
      "val 0:00:12.687606 loss: 6.0638 accuracy: 0.3958\n",
      "Elapsed time: 0:01:48.005154\n",
      "\n",
      "Epoch 20/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:37.062906 loss: 0.9865 accuracy: 0.6418\n",
      "Num samples 6375\n",
      "val 0:00:12.195055 loss: 5.5440 accuracy: 0.3991\n",
      "Elapsed time: 0:01:49.258653\n",
      "\n",
      "Epoch 21/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.753743 loss: 0.9710 accuracy: 0.6411\n",
      "Num samples 6375\n",
      "val 0:00:12.131851 loss: 5.1079 accuracy: 0.4006\n",
      "Elapsed time: 0:01:46.886456\n",
      "\n",
      "Epoch 22/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.909401 loss: 0.9764 accuracy: 0.6474\n",
      "Num samples 6375\n",
      "val 0:00:12.709875 loss: 6.8924 accuracy: 0.3975\n",
      "Elapsed time: 0:01:47.620156\n",
      "\n",
      "Epoch 23/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.326983 loss: 0.9851 accuracy: 0.6472\n",
      "Num samples 6375\n",
      "val 0:00:12.648403 loss: 5.4397 accuracy: 0.4017\n",
      "Elapsed time: 0:01:48.976289\n",
      "\n",
      "Epoch 24/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.292951 loss: 0.9741 accuracy: 0.6470\n",
      "Num samples 6375\n",
      "val 0:00:12.646255 loss: 5.5916 accuracy: 0.4000\n",
      "Elapsed time: 0:01:48.939996\n",
      "\n",
      "Epoch 25/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.381934 loss: 0.9698 accuracy: 0.6462\n",
      "Num samples 6375\n",
      "val 0:00:12.547987 loss: 4.8595 accuracy: 0.4014\n",
      "Elapsed time: 0:01:48.930686\n",
      "\n",
      "Epoch 26/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.485311 loss: 0.9738 accuracy: 0.6451\n",
      "Num samples 6375\n",
      "val 0:00:11.954821 loss: 4.9890 accuracy: 0.4050\n",
      "Elapsed time: 0:01:44.440988\n",
      "\n",
      "Epoch 27/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.552881 loss: 0.9666 accuracy: 0.6467\n",
      "Num samples 6375\n",
      "val 0:00:11.897653 loss: 4.4027 accuracy: 0.4069\n",
      "Elapsed time: 0:01:43.451291\n",
      "\n",
      "Epoch 28/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.736447 loss: 0.9544 accuracy: 0.6508\n",
      "Num samples 6375\n",
      "val 0:00:12.037029 loss: 5.9621 accuracy: 0.3980\n",
      "Elapsed time: 0:01:43.774290\n",
      "\n",
      "Epoch 29/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.643084 loss: 0.9734 accuracy: 0.6486\n",
      "Num samples 6375\n",
      "val 0:00:11.949557 loss: 4.3853 accuracy: 0.4042\n",
      "Elapsed time: 0:01:43.593463\n",
      "\n",
      "Epoch 30/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.994320 loss: 0.9676 accuracy: 0.6533\n",
      "Num samples 6375\n",
      "val 0:00:12.599160 loss: 4.4201 accuracy: 0.4053\n",
      "Elapsed time: 0:01:48.594348\n",
      "\n",
      "Epoch 31/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.392432 loss: 0.9415 accuracy: 0.6515\n",
      "Num samples 6375\n",
      "val 0:00:12.721320 loss: 4.9963 accuracy: 0.4017\n",
      "Elapsed time: 0:01:49.114616\n",
      "\n",
      "Epoch 32/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.490819 loss: 0.9626 accuracy: 0.6547\n",
      "Num samples 6375\n",
      "val 0:00:12.696318 loss: 4.6290 accuracy: 0.4104\n",
      "Elapsed time: 0:01:49.190421\n",
      "\n",
      "Epoch 33/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.953801 loss: 0.9510 accuracy: 0.6506\n",
      "Num samples 6375\n",
      "val 0:00:12.083073 loss: 5.1706 accuracy: 0.4045\n",
      "Elapsed time: 0:01:45.037656\n",
      "\n",
      "Epoch 34/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.945940 loss: 0.9482 accuracy: 0.6523\n",
      "Num samples 6375\n",
      "val 0:00:11.989662 loss: 4.6999 accuracy: 0.4017\n",
      "Elapsed time: 0:01:43.936547\n",
      "\n",
      "Epoch 35/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.148239 loss: 0.9412 accuracy: 0.6564\n",
      "Num samples 6375\n",
      "val 0:00:12.102806 loss: 5.3489 accuracy: 0.4019\n",
      "Elapsed time: 0:01:44.251984\n",
      "\n",
      "Epoch 36/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.662902 loss: 0.9496 accuracy: 0.6559\n",
      "Num samples 6375\n",
      "val 0:00:11.984693 loss: 4.7599 accuracy: 0.4140\n",
      "Elapsed time: 0:01:47.650865\n",
      "\n",
      "Epoch 37/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.445390 loss: 0.9492 accuracy: 0.6578\n",
      "Num samples 6375\n",
      "val 0:00:12.031265 loss: 4.6545 accuracy: 0.3987\n",
      "Elapsed time: 0:01:44.477509\n",
      "\n",
      "Epoch 38/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.077905 loss: 0.9321 accuracy: 0.6579\n",
      "Num samples 6375\n",
      "val 0:00:11.956241 loss: 4.6406 accuracy: 0.4099\n",
      "Elapsed time: 0:01:45.035012\n",
      "\n",
      "Epoch 39/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.901776 loss: 0.9306 accuracy: 0.6610\n",
      "Num samples 6375\n",
      "val 0:00:12.586820 loss: 4.9777 accuracy: 0.4069\n",
      "Elapsed time: 0:01:45.489425\n",
      "\n",
      "Epoch 40/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.068323 loss: 0.9397 accuracy: 0.6599\n",
      "Num samples 6375\n",
      "val 0:00:12.180112 loss: 5.4308 accuracy: 0.4086\n",
      "Elapsed time: 0:01:48.249300\n",
      "\n",
      "Epoch 41/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.942581 loss: 0.9507 accuracy: 0.6610\n",
      "Num samples 6375\n",
      "val 0:00:11.991653 loss: 5.4869 accuracy: 0.4009\n",
      "Elapsed time: 0:01:43.935080\n",
      "\n",
      "Epoch 42/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.944693 loss: 0.9398 accuracy: 0.6598\n",
      "Num samples 6375\n",
      "val 0:00:12.004042 loss: 4.3599 accuracy: 0.4199\n",
      "Elapsed time: 0:01:43.951889\n",
      "\n",
      "Epoch 43/59\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num samples 50000\n",
      "train 0:01:32.168537 loss: 0.9234 accuracy: 0.6613\n",
      "Num samples 6375\n",
      "val 0:00:12.006393 loss: 4.0248 accuracy: 0.4187\n",
      "Elapsed time: 0:01:44.175667\n",
      "\n",
      "Epoch 44/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.943241 loss: 0.9327 accuracy: 0.6625\n",
      "Num samples 6375\n",
      "val 0:00:11.973558 loss: 4.5963 accuracy: 0.4104\n",
      "Elapsed time: 0:01:43.917574\n",
      "\n",
      "Epoch 45/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.773142 loss: 0.9347 accuracy: 0.6598\n",
      "Num samples 6375\n",
      "val 0:00:12.553264 loss: 3.8805 accuracy: 0.4196\n",
      "Elapsed time: 0:01:46.327330\n",
      "\n",
      "Epoch 46/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.834409 loss: 0.9298 accuracy: 0.6640\n",
      "Num samples 6375\n",
      "val 0:00:12.550517 loss: 4.4783 accuracy: 0.4182\n",
      "Elapsed time: 0:01:48.385803\n",
      "\n",
      "Epoch 47/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.948553 loss: 0.9351 accuracy: 0.6652\n",
      "Num samples 6375\n",
      "val 0:00:12.607567 loss: 4.7004 accuracy: 0.4085\n",
      "Elapsed time: 0:01:48.556997\n",
      "\n",
      "Epoch 48/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.938042 loss: 0.9326 accuracy: 0.6635\n",
      "Num samples 6375\n",
      "val 0:00:12.562334 loss: 4.0226 accuracy: 0.4173\n",
      "Elapsed time: 0:01:48.501211\n",
      "\n",
      "Epoch 49/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:32.534904 loss: 0.9259 accuracy: 0.6655\n",
      "Num samples 6375\n",
      "val 0:00:11.948730 loss: 4.4150 accuracy: 0.4187\n",
      "Elapsed time: 0:01:44.484800\n",
      "\n",
      "Epoch 50/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:34.240318 loss: 0.9277 accuracy: 0.6613\n",
      "Num samples 6375\n",
      "val 0:00:12.566927 loss: 4.6054 accuracy: 0.4130\n",
      "Elapsed time: 0:01:46.808152\n",
      "\n",
      "Epoch 51/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.629989 loss: 0.9370 accuracy: 0.6624\n",
      "Num samples 6375\n",
      "val 0:00:12.538041 loss: 4.5618 accuracy: 0.4300\n",
      "Elapsed time: 0:01:48.171096\n",
      "\n",
      "Epoch 52/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.862685 loss: 0.9323 accuracy: 0.6671\n",
      "Num samples 6375\n",
      "val 0:00:12.558466 loss: 4.7291 accuracy: 0.4122\n",
      "Elapsed time: 0:01:48.422112\n",
      "\n",
      "Epoch 53/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.891378 loss: 0.9243 accuracy: 0.6665\n",
      "Num samples 6375\n",
      "val 0:00:12.517007 loss: 4.9608 accuracy: 0.4044\n",
      "Elapsed time: 0:01:48.409240\n",
      "\n",
      "Epoch 54/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:35.913488 loss: 0.9262 accuracy: 0.6735\n",
      "Num samples 6375\n",
      "val 0:00:11.987215 loss: 4.5197 accuracy: 0.4108\n",
      "Elapsed time: 0:01:47.901576\n",
      "\n",
      "Epoch 55/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:31.715587 loss: 0.9290 accuracy: 0.6636\n",
      "Num samples 6375\n",
      "val 0:00:12.201329 loss: 5.3647 accuracy: 0.4019\n",
      "Elapsed time: 0:01:43.917765\n",
      "\n",
      "Epoch 56/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.885692 loss: 0.9199 accuracy: 0.6655\n",
      "Num samples 6375\n",
      "val 0:00:12.091285 loss: 4.3536 accuracy: 0.4216\n",
      "Elapsed time: 0:01:45.977813\n",
      "\n",
      "Epoch 57/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:33.015637 loss: 0.9279 accuracy: 0.6656\n",
      "Num samples 6375\n",
      "val 0:00:12.728252 loss: 3.1709 accuracy: 0.4290\n",
      "Elapsed time: 0:01:45.744978\n",
      "\n",
      "Epoch 58/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.844857 loss: 0.9237 accuracy: 0.6652\n",
      "Num samples 6375\n",
      "val 0:00:12.813831 loss: 4.2233 accuracy: 0.4158\n",
      "Elapsed time: 0:01:49.659527\n",
      "\n",
      "Epoch 59/59\n",
      "----------\n",
      "Num samples 50000\n",
      "train 0:01:36.706013 loss: 0.9211 accuracy: 0.6659\n",
      "Num samples 6375\n",
      "val 0:00:12.600847 loss: 4.2600 accuracy: 0.4180\n",
      "Elapsed time: 0:01:49.307810\n",
      "\n",
      "Training complete in 106m 45s\n",
      "Best acc: 0.429961\n",
      "\n",
      "Metrics\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix of Patches\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>9955</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9721</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9046</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6154</td>\n",
       "      <td>12</td>\n",
       "      <td>357</td>\n",
       "      <td>3473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1   2    3     4\n",
       "0  13  9955   0    6    26\n",
       "1   2  9721   0    7   270\n",
       "2   2  9046  44   54   854\n",
       "3   4  6154  12  357  3473\n",
       "4   0   493   1   16  9490"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion Matrix of Whole Images\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1  2  3    4\n",
       "0  0  400  0  0    0\n",
       "1  0  399  0  0    1\n",
       "2  0  382  0  0   18\n",
       "3  0  289  0  0  111\n",
       "4  0   13  0  0  387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix of Patches\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2429</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1639</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1  2    3    4\n",
       "0  18  2429  0    3    0\n",
       "1   2  1639  0    3    6\n",
       "2  11   571  2   40   26\n",
       "3  34   303  1  211  101\n",
       "4   2    39  1   62  871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Confusion Matrix of Whole Images\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2  3   4\n",
       "0  0  98  0  0   0\n",
       "1  0  66  0  0   0\n",
       "2  0  23  0  2   1\n",
       "3  1  14  0  8   3\n",
       "4  0   0  0  1  38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions file: predict_c2_h2_nFrnLAKTySysHV2ngdtruW.csv\n",
      "1: 145\n",
      "4: 55\n",
      "Finished generating predictions to predict_c2_h2_nFrnLAKTySysHV2ngdtruW.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(2048, 256, 0.5).to(device)\n",
    "run_trial(\"h2\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H3: 512-64-5\n",
    "\n",
    "* DNN Structure: 512-64-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(512, 64, 0.5).to(device)\n",
    "run_trial(\"h3\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H4: Best from above, dropout 0.25\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.25\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n1, n2, 0.25).to(device)\n",
    "run_trial(\"h4\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H5: Best from above, dropout 0.1\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.1\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n1, n2, 0.1).to(device)\n",
    "run_trial(\"h5\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H6: Best from above, skewed class weights\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,5,5,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n1, n2, 0.5).to(device)\n",
    "run_trial(\"h6\", model, class_weights=[1., 1., 5., 5., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H7: Best from above, batch normalization\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.5\n",
    "* Class weights: \n",
    "* Batch normalization: yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n1, n2, 0.5, batch_normalization=True).to(device)\n",
    "run_trial(\"h7\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimal_n1 = 1024\n",
    "optimal_n2 = 128\n",
    "optimal_d = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with all C2 data and optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model(optimal_n1, optimal_n2, optimal_d).to(device)\n",
    "# model.load_state_dict(torch.load('cnn_pytorch_c2.pt'))\n",
    "y_hat_test = train_and_test(model, group_3(), num_epochs=40)\n",
    "predictions_file = \"predict_c2_{}.csv\".format(shortuuid.uuid())\n",
    "print('predictions file:', predictions_file)\n",
    "predict_whole_images(y_hat_test, PATCH_ROWS, PATCH_COLUMNS, predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "print(y_hat_test)\n",
    "torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cnn_pytorch_c2.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
