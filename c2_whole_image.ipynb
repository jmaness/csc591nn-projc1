{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "c2_whole_image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXjHzAiE7fEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3f22b73-2c8c-46d6-9af6-3f9391b1e90a"
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python==3.4.2.17\n",
        "!pip install pandas\n",
        "!pip install pillow\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-image\n",
        "!pip install scikit-optimize\n",
        "!pip install shortuuid\n",
        "!pip install torch\n",
        "!pip install torchsummary\n",
        "!pip install torchvision\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.2)\n",
            "Collecting opencv-contrib-python==3.4.2.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/29/fc60b2de1713aa92946992544329f20ccb5e4ba26290f403e04b7da44105/opencv_contrib_python-3.4.2.17-cp36-cp36m-manylinux1_x86_64.whl (30.6MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.17) (1.18.2)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.2.17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (0.16.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.19.0->scikit-image) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.14.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.7.4\n",
            "Collecting shortuuid\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Installing collected packages: shortuuid\n",
            "Successfully installed shortuuid-1.0.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": true,
        "id": "noqAinN-7cMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import csv\n",
        "import cv2\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "from collections import Counter\n",
        "from datetime import timedelta\n",
        "import shortuuid\n",
        "\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from torchvision import models, transforms\n",
        "\n",
        "def ann_file(data_dir):\n",
        "    return os.path.join(data_dir, \"TrainAnnotations.csv\")\n",
        "\n",
        "\n",
        "TRAIN_DATA_DIR = \"/content/drive/My Drive/TrainData-C2\"\n",
        "TRAIN_DATA_ANN_FILE = ann_file(TRAIN_DATA_DIR)\n",
        "\n",
        "TRAIN_SPLIT_DATA_DIR           = \"/tmp/data/train/split\"\n",
        "TRAIN_SPLIT_ANN_FILE           = ann_file(TRAIN_SPLIT_DATA_DIR)\n",
        "TRAIN_SPLIT_AUGMENTED_DATA_DIR = \"/tmp/data/train/augmented\"\n",
        "TRAIN_SPLIT_AUGMENTED_ANN_FILE = ann_file(TRAIN_SPLIT_AUGMENTED_DATA_DIR)\n",
        "\n",
        "TRAIN_ALL_AUGMENTED_DATA_DIR   = \"/tmp/data/train-all/augmented\"\n",
        "TRAIN_ALL_AUGMENTED_ANN_FILE   = ann_file(TRAIN_ALL_AUGMENTED_DATA_DIR)\n",
        "\n",
        "VAL_SPLIT_DATA_DIR         = \"/tmp/data/val/split\"\n",
        "VAL_SPLIT_ANN_FILE         = ann_file(VAL_SPLIT_DATA_DIR)\n",
        "\n",
        "TEST_DATA_DIR         = \"/content/drive/My Drive/TestData/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxpfGGthD2xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "1a14c0a6-2f3d-47ee-95d6-2a8f535b8e9b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfRD-DhA7cM2",
        "colab_type": "text"
      },
      "source": [
        "## Enable GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "NYQfmTAd7cM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG8hTxRoFwUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5f5199b-2be9-4f9b-eae4-3c436cb075ce"
      },
      "source": [
        "device"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewAYY8cR7cM7",
        "colab_type": "text"
      },
      "source": [
        "## Split data\n",
        "Generate random, stratified 80/20 split for training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQu2uA8y7cM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7513456c-8b04-4262-d716-067df9fb0759"
      },
      "source": [
        "if (os.path.exists(TRAIN_SPLIT_DATA_DIR) or os.path.exists(VAL_SPLIT_DATA_DIR)):\n",
        "    print(\"Data directories for splits already exist. Skipping\")\n",
        "else:\n",
        "    # Generate 80/20 split\n",
        "\n",
        "    print(\"Reading {} annotations...\".format(TRAIN_DATA_ANN_FILE))\n",
        "    ann_df = pd.read_csv(TRAIN_DATA_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
        "\n",
        "    print(\"Splitting data into training and validation sets...\")\n",
        "    train_df, val_df = train_test_split(ann_df,\n",
        "                                        train_size=0.80,\n",
        "                                        random_state=138,\n",
        "                                        shuffle=True,\n",
        "                                        stratify=ann_df[['annotation']].to_numpy(dtype=np.int32).flatten())\n",
        "\n",
        "    os.makedirs(TRAIN_SPLIT_DATA_DIR)\n",
        "    os.makedirs(VAL_SPLIT_DATA_DIR)\n",
        "    \n",
        "    print(\"Copying files for training split...\")\n",
        "    for _, row in train_df.iterrows():\n",
        "        filename = row['file_name']\n",
        "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
        "        dest = os.path.join(TRAIN_SPLIT_DATA_DIR, filename)\n",
        "        shutil.copyfile(src, dest)\n",
        "        \n",
        "    print(\"Generating training split annotations...\")\n",
        "    train_df.sort_values('file_name').to_csv(TRAIN_SPLIT_ANN_FILE, index=False)\n",
        "        \n",
        "    print(\"Copying files for validation split...\")\n",
        "    for _, row in val_df.iterrows():\n",
        "        filename = row['file_name']\n",
        "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
        "        dest = os.path.join(VAL_SPLIT_DATA_DIR, filename)\n",
        "        shutil.copyfile(src, dest)\n",
        "        \n",
        "    print(\"Generating validation split annotations...\")\n",
        "    val_df.sort_values('file_name').to_csv(VAL_SPLIT_ANN_FILE, index=False)\n",
        "        \n",
        "    print(\"Done.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading /content/drive/My Drive/TrainData-C2/TrainAnnotations.csv annotations...\n",
            "Splitting data into training and validation sets...\n",
            "Copying files for training split...\n",
            "Generating training split annotations...\n",
            "Copying files for validation split...\n",
            "Generating validation split annotations...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIXAqD5j7cNB",
        "colab_type": "text"
      },
      "source": [
        "## Augment data\n",
        "Because the training dataset is unbalanced, augment the training data set by generating\n",
        "new images for the lower numbered samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NofMYY9M7cNC",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "aGyzq4Jg7cNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_STATE = 13\n",
        "\n",
        "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return filename.endswith(IMG_EXTENSIONS)\n",
        "\n",
        "\n",
        "def augment_data(src_dir, src_ann_file, dest_dir, dest_ann_file, class_sample_count=500):\n",
        "    os.makedirs(dest_dir)\n",
        "\n",
        "    ann_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'}) \n",
        "    new_samples = {}\n",
        "    \n",
        "    for i in range(5):\n",
        "        class_df = ann_df.query(\"annotation == '{}'\".format(i))\n",
        "        num_class_samples = class_df.shape[0]\n",
        "        num_to_create = class_sample_count - num_class_samples\n",
        "            \n",
        "        print(\"Creating {} images for class {}\".format(num_to_create, i))\n",
        "        samples = class_df.sample(n=num_to_create, replace=True, random_state=RANDOM_STATE)\n",
        "    \n",
        "        for idx, row in samples.iterrows():\n",
        "            new_filename = row['file_name'].split('.')[0] + \"_\" + shortuuid.uuid() + \".png\"\n",
        "    \n",
        "            # Apply transformations to each randomly selected sample\n",
        "            img = Image.open(src_dir + \"/\" + row['file_name'])\n",
        "            image_transforms = transforms.Compose([\n",
        "                transforms.RandomAffine(degrees=20, translate=(0.2, 0.2)),\n",
        "                transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "                transforms.RandomResizedCrop((480, 640), scale=(1.0, 1.2)),\n",
        "            ])\n",
        "            transformed_img = image_transforms(img)\n",
        "            transformed_img.save(os.path.join(dest_dir, new_filename))\n",
        "    \n",
        "            new_samples[new_filename] = row['annotation']\n",
        "    \n",
        "    # Add to new dataframe\n",
        "    balanced_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'})\n",
        "    balanced_df = balanced_df.append(pd.DataFrame.from_records([(k, v) for k, v in new_samples.items()],\n",
        "                                                 columns=['file_name', 'annotation']))\n",
        "    \n",
        "    # Write new annotations\n",
        "    balanced_df.sort_values('file_name').to_csv(dest_ann_file, index=False)\n",
        "    \n",
        "    # Copy images from training data split\n",
        "    for file in glob.glob(src_dir + \"/*\"):\n",
        "        if is_image_file(file):\n",
        "            shutil.copy(file, os.path.join(dest_dir, os.path.basename(file)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "vd_Rqbpq7cNI",
        "colab_type": "text"
      },
      "source": [
        "### Run data augmentation\n",
        "\n",
        "Perform the data augmentation on the training data set split to balance the class samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "VW9-Evfi7cNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c3cf0bef-7ea2-4fc4-ead4-44e8a84911f5"
      },
      "source": [
        "if os.path.exists(TRAIN_SPLIT_AUGMENTED_DATA_DIR):\n",
        "    print(\"Augmented SPLIT training data already exists. Skipping.\")\n",
        "else:\n",
        "    print(\"Balancing class samples for SPLIT training data...\")\n",
        "    augment_data(TRAIN_SPLIT_DATA_DIR,\n",
        "                 TRAIN_SPLIT_ANN_FILE,\n",
        "                 TRAIN_SPLIT_AUGMENTED_DATA_DIR,\n",
        "                 TRAIN_SPLIT_AUGMENTED_ANN_FILE,\n",
        "                 class_sample_count=400)    \n",
        "    print(\"Done.\")\n",
        "\n",
        "if os.path.exists(TRAIN_ALL_AUGMENTED_DATA_DIR):\n",
        "    print(\"Augmented ALL training data already exists. Skipping.\")\n",
        "else:\n",
        "    print(\"Balancing class samples for ALL training data...\")\n",
        "    augment_data(TRAIN_DATA_DIR,\n",
        "                 TRAIN_DATA_ANN_FILE,\n",
        "                 TRAIN_ALL_AUGMENTED_DATA_DIR,\n",
        "                 TRAIN_ALL_AUGMENTED_ANN_FILE,\n",
        "                 class_sample_count=500)\n",
        "    print(\"Done.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Balancing class samples for SPLIT training data...\n",
            "Creating 10 images for class 0\n",
            "Creating 137 images for class 1\n",
            "Creating 296 images for class 2\n",
            "Creating 295 images for class 3\n",
            "Creating 242 images for class 4\n",
            "Done.\n",
            "Balancing class samples for ALL training data...\n",
            "Creating 12 images for class 0\n",
            "Creating 171 images for class 1\n",
            "Creating 370 images for class 2\n",
            "Creating 369 images for class 3\n",
            "Creating 303 images for class 4\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ka1mtady7cNN",
        "colab_type": "text"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Given a directory of images and a CSV file of annotations, this defines a PyTorch Dataset which will load an image from disk and apply all configure transformations and return a tuple containing the image and label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": true,
        "id": "7MB1CoV27cNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SoybeanDataset(torch.utils.data.dataset.Dataset):\n",
        "    def __init__(self, data_path, ann_df, transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to images\n",
        "            ann_df (string): pandas data frame containing file names and annotations\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        self.data_path = data_path\n",
        "        \n",
        "        self.data = ann_df\n",
        "        self.labels = np.asarray(self.data.iloc[:, 1])\n",
        "        \n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #print('index:', index)\n",
        "        image_label = int(self.labels[index])\n",
        "        img_path = os.path.join(self.data_path, self.data.file_name[index])\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        \n",
        "        # Transform image\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "            \n",
        "        # Return image and the label\n",
        "        return img, image_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "\n",
        "class SoybeanTestDatasetFolder(torch.utils.data.IterableDataset):\n",
        "    def __init__(self, data_path, transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): path to images\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        self.data_path = data_path\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        self.images = []\n",
        "        \n",
        "        for root, _, fnames in sorted(os.walk(data_path, followlinks=True)):\n",
        "            for fname in sorted(fnames):\n",
        "                path = fname\n",
        "                if is_image_file(path):\n",
        "                    self.images.append(path)\n",
        "\n",
        "                                       \n",
        "    def image_gen(self):\n",
        "        for i in self.images:\n",
        "            img_path = os.path.join(self.data_path, i)\n",
        "            img = Image.open(img_path)\n",
        "        \n",
        "            # Transform image\n",
        "            if self.transforms is not None:\n",
        "                img = self.transforms(img)\n",
        "                \n",
        "            yield img\n",
        "            \n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.image_gen())\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "\n",
        "\n",
        "class SoybeanDataGroup():\n",
        "    def __init__(self, class_weights, \n",
        "                 train_dataloader,\n",
        "                 val_dataloader=None,\n",
        "                 test_dataloader=None):\n",
        "        self.class_weights = class_weights\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "\n",
        "\n",
        "def compute_class_weights(df, y_col):\n",
        "    \"\"\"\n",
        "    Returns a list of class labels to 'balanced' weights based on the\n",
        "    frequency of the weights across the labels in the specified dataframe\n",
        "    \"\"\"\n",
        "    y = df[[y_col]].to_numpy(dtype=np.int32).flatten()\n",
        "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
        "    return torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO5a1hNZ7cNS",
        "colab_type": "text"
      },
      "source": [
        "### Common image transformations\n",
        "These images transformations will apply to both train and validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "hMVSt8Lt7cNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SamplewiseCenterNormalize(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Normalized Tensor image.\n",
        "        \"\"\"\n",
        "        \n",
        "        return torch.div(torch.add(tensor, torch.mul(torch.mean(tensor), -1)), torch.std(tensor) + 1e-6)\n",
        "        \n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__\n",
        "\n",
        "\n",
        "\n",
        "DATA_TRANSFORMS = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    #transforms.RandomAffine(degrees=20, translate=(0.2, 0.2)),\n",
        "    transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), shear=10, scale=(1.0, 1.2)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    #transforms.RandomCrop(size=(480,640)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    # SamplewiseCenterNormalize()\n",
        "\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "TEST_DATA_TRANSFORMS = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    # SamplewiseCenterNormalize()\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXx52-qM7cNU",
        "colab_type": "text"
      },
      "source": [
        "### Train 0.80/Val 0.20 Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "U9P2484z7cNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_val_split_group(class_weights=None):\n",
        "    \n",
        "    print(\"Reading annotations...\")\n",
        "    train_ann_df = pd.read_csv(TRAIN_SPLIT_AUGMENTED_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
        "    val_ann_df   = pd.read_csv(VAL_SPLIT_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
        "    \n",
        "    if class_weights is None:\n",
        "        print(\"Computing class weights...\")\n",
        "        class_weights = compute_class_weights(train_ann_df, 'annotation')\n",
        "        print(class_weights)\n",
        "    else:\n",
        "        print(\"Using class weights:\", class_weights)\n",
        "        \n",
        "    train_dataset = SoybeanDataset(TRAIN_SPLIT_AUGMENTED_DATA_DIR, train_ann_df, transforms=DATA_TRANSFORMS)\n",
        "    val_dataset = SoybeanDataset(VAL_SPLIT_DATA_DIR, val_ann_df, transforms=TEST_DATA_TRANSFORMS)\n",
        "    test_dataset  = SoybeanTestDatasetFolder(TEST_DATA_DIR, transforms=TEST_DATA_TRANSFORMS)\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   pin_memory=True, \n",
        "                                                   num_workers=16)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                                 batch_size=BATCH_SIZE,\n",
        "                                                 pin_memory=True,\n",
        "                                                 num_workers=16)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  pin_memory=True,\n",
        "                                                  num_workers=0)\n",
        "    \n",
        "    return SoybeanDataGroup(class_weights, train_dataloader, val_dataloader, test_dataloader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBkL7NWZ7cNW",
        "colab_type": "text"
      },
      "source": [
        "### Train 100%\n",
        "\n",
        "Train with all the data in the `TrainData-C2` dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "m0_EUTtT7cNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def all_train_data_group(class_weights=None):\n",
        "    print(\"Reading annotations...\")\n",
        "    ann_df = pd.read_csv(TRAIN_DATA_AUGMENTED_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
        "    \n",
        "    if class_weights is None:\n",
        "        print(\"Computing class weights...\")\n",
        "        class_weights = compute_class_weights(ann_df, 'annotation')\n",
        "        print(class_weights)\n",
        "    else:\n",
        "        print(\"Using class weights:\", class_weights)\n",
        "\n",
        "    train_dataset = SoybeanDataset(TRAIN_DATA_AUGMENTED_DATA_DIR, ann_df, transforms=DATA_TRANSFORMS)\n",
        "    test_dataset  = SoybeanTestDatasetFolder(TEST_DATA_DIR, transforms=TEST_DATA_TRANSFORMS)\n",
        "    \n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   pin_memory=True, \n",
        "                                                   num_workers=16)\n",
        "    \n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  pin_memory=True,\n",
        "                                                  num_workers=0)\n",
        "    \n",
        "    return SoybeanDataGroup(class_weights, train_dataloader, None, test_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2gd8pv57cNZ",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "This model is based on the VGG16 network with custom classifier layers \n",
        "with the feature layers initialized with weights based on the ImageNet data. \n",
        "\n",
        "The number of neurons and dropout rates in the classifier layers are parameterized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "aw8JROHi7cNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(n1, n2, dropout, batch_normalization=False):\n",
        "    if batch_normalization:\n",
        "        model = models.vgg16_bn(pretrained=True)\n",
        "    else:\n",
        "        model = models.vgg16(pretrained=True) \n",
        "\n",
        "    # Freeze training for all layers\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    \n",
        "    # Replace the VGG16 classifier with a custom classifier for soybean wilting \n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(512 * 1 * 1, n1, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.Linear(n1, n2, bias=True),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=dropout),\n",
        "        nn.Linear(n2, 5, bias=True)\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZpxLMY7cNc",
        "colab_type": "text"
      },
      "source": [
        "## Training loop\n",
        "For training and validation, this trains a model across a configured number of epochs and outputs the training and validation loss and accuracy for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "5C6V4fu97cNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, dataloaders, num_epochs=25):\n",
        "    \"\"\"\n",
        "    Trains the specified neural network model\n",
        "    \n",
        "    Args:\n",
        "        model:         - neural network model to train\n",
        "        criterion:     - loss function\n",
        "        optimizer:     - gradient descent optimization algorithm\n",
        "        dataloaders:   - dict of DataLoaders for training and validation data\n",
        "        num_epochs:    - number of epochs to train model\n",
        "    Returns:\n",
        "        model   - trained model with weights from the epoch with the best validation accuracy\n",
        "        history - dict of training and validation loss and accuracy for all epochs\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "    \n",
        "    # summary(model, input_size=(3, 224, 224))\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    \n",
        "    history = {'train': {'loss': [], 'acc': []}}\n",
        "    phases = ['train']\n",
        "    if ('val' in dataloaders and dataloaders['val'] is not None):\n",
        "        phases += ['val']\n",
        "        history['val'] = {'loss': [], 'acc': []}\n",
        "    \n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start = time.time()\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and optionally, a validation phase\n",
        "        for phase in phases:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                \n",
        "            phase_start = time.time()\n",
        "\n",
        "            sample_count = 0\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:               \n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "                        nn.utils.clip_grad_value_(model.parameters(), 0.5)\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                sample_count += inputs.size(0)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += preds.eq(labels.data.view_as(preds)).cpu().sum()\n",
        "            \n",
        "            print('Num samples', sample_count)\n",
        "            \n",
        "            epoch_loss = running_loss / sample_count\n",
        "            epoch_acc = running_corrects.double() / sample_count\n",
        "            \n",
        "            history[phase]['loss'].append(epoch_loss)\n",
        "            history[phase]['acc'].append(epoch_acc)\n",
        "            \n",
        "            phase_end = time.time()\n",
        "            phase_elapsed = phase_end - phase_start\n",
        "\n",
        "            print('{} {} loss: {:.4f} accuracy: {:.4f}'.format(\n",
        "                phase, str(timedelta(seconds=phase_elapsed)), epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if ('val' not in phases or phase == 'val') and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        epoch_end = time.time()\n",
        "        epoch_elapsed = epoch_end - epoch_start\n",
        "        print('Elapsed time: {}'.format(str(timedelta(seconds=epoch_elapsed))))\n",
        "        \n",
        "        print()\n",
        "        \n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    \n",
        "    return model, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35400hD97cNe",
        "colab_type": "text"
      },
      "source": [
        "## Train models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": false,
        "id": "lsjkwx-Y7cNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "def get_sample_count(dataset, sampler):\n",
        "    if (sampler is not None):\n",
        "        return len(sampler)\n",
        "    elif (dataset is not None):\n",
        "        return len(dataset)\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "\n",
        "def train(model, group, num_epochs=20):\n",
        "    criterion = nn.CrossEntropyLoss(weight=group.class_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-07)\n",
        "    \n",
        "    dataloaders = {\n",
        "        'train': group.train_dataloader,\n",
        "        'val': group.val_dataloader\n",
        "    }\n",
        " \n",
        "    model_trained, history = train_model(model, criterion, optimizer, dataloaders, num_epochs)\n",
        "    \n",
        "    \n",
        "    return model_trained, history\n",
        "\n",
        "\n",
        "def get_all_labels(loader):\n",
        "    all_labels = torch.tensor([], dtype=torch.long)\n",
        "    for batch in loader:\n",
        "        _, labels = batch\n",
        "        all_labels = torch.cat((all_labels, labels), dim=0)\n",
        "    return all_labels\n",
        "\n",
        "\n",
        "def plot_metrics(model, history, train_dataloader, val_dataloader=None):\n",
        "    \n",
        "    print()\n",
        "    print('Metrics')\n",
        "    print('-' * 10)\n",
        "    \n",
        "    # Create count of the number of epochs\n",
        "    epoch_count = range(1, len(history['train']['loss']) + 1)\n",
        "\n",
        "    # Visualize loss history\n",
        "    plt.plot(epoch_count, history['train']['loss'], 'g-')\n",
        "    loss_legend = ['Training Loss']\n",
        "    \n",
        "    if ('val' in history and history['val'] is not None):\n",
        "        plt.plot(epoch_count, history['val']['loss'], 'b-')\n",
        "        loss_legend += ['Validation Loss']\n",
        "        \n",
        "    plt.legend(loss_legend)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()\n",
        "    \n",
        "    # Visualize accuracy history\n",
        "    plt.plot(epoch_count, history['train']['acc'], 'g-')\n",
        "    acc_legend = ['Training Accuracy']\n",
        "    \n",
        "    if ('val' in history and history['val'] is not None):\n",
        "        plt.plot(epoch_count, history['val']['acc'], 'b-')\n",
        "        acc_legend += ['Validation Accuracy']\n",
        "    \n",
        "    plt.legend(acc_legend)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    # Training confusion matrix\n",
        "    #train_predictions = predict(model, train_dataloader).cpu().numpy()\n",
        "    \n",
        "    #print(\"Training Confusion Matrix\")\n",
        "    #print(\"-\" * 30)\n",
        "    #print_confusion_matrix(get_all_labels(train_dataloader).cpu().numpy(),\n",
        "    #                       train_predictions)\n",
        "        \n",
        "    # Validation confusion matrix\n",
        "    #if val_dataloader is not None:\n",
        "    #    val_predictions = predict(model, val_dataloader).cpu().numpy()\n",
        "        \n",
        "    #    print(\"Validation Confusion Matrix\")\n",
        "    #    print(\"-\" * 30)\n",
        "    #    print_confusion_matrix(get_all_labels(val_dataloader).cpu().numpy(),\n",
        "    #                           val_predictions)\n",
        "        \n",
        "\n",
        "def train_and_test(model, group, num_epochs=60):\n",
        "    model_trained, history = train(model, group, num_epochs)\n",
        "    \n",
        "    # Plot history metrics\n",
        "    plot_metrics(model_trained, history, group.train_dataloader, group.val_dataloader)\n",
        "    \n",
        "    # Classify test data\n",
        "    return predict(model_trained, group.test_dataloader)\n",
        "\n",
        "\n",
        "def predict(model, dataloader):\n",
        "    predictions = torch.tensor([], dtype=torch.long).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            if (type(data) is list):\n",
        "                images = data[0].to(device)\n",
        "            else:\n",
        "                images = data.to(device)\n",
        "            model.eval()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions = torch.cat((predictions, predicted))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def one_hot_encode_predictions(predictions, csvfile):\n",
        "\n",
        "    #for k, v in sorted(Counter(predictions).items()): \n",
        "    #    print(str(k) + ': '+ str(v))    \n",
        "\n",
        "    one_hots = [np.zeros((5,1)) for pred in predictions]\n",
        "    for i in range(len(one_hots)):\n",
        "        pred = predictions[i]  # the index of the one-hot encoding\n",
        "        one_hots[i][pred] = 1\n",
        "    with open(csvfile, 'w') as predictions_file:\n",
        "        writer = csv.writer(predictions_file)\n",
        "        for pred in one_hots:\n",
        "            pred = np.array(pred, dtype=int)\n",
        "            writer.writerow(pred.T.tolist()[0])\n",
        "    print('Finished generating predictions to', csvfile)\n",
        "\n",
        "\n",
        "def print_confusion_matrix(y, y_hat):\n",
        "    confusion_matrix = np.zeros((5, 5))\n",
        "    labels = [0, 1, 2, 3, 4]\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(len(labels)):\n",
        "            ground_truth = y==labels[i]\n",
        "            prediction = y_hat==labels[j]\n",
        "            confusion_matrix[i, j] = sum(np.bitwise_and(ground_truth, prediction))\n",
        "    df = pd.DataFrame(confusion_matrix, dtype=int)\n",
        "    display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mbw-waF7cNg",
        "colab_type": "text"
      },
      "source": [
        "### Train and Test - 80/20 Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": true,
        "id": "UTDUHqwa7cNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(1024, 128, 0.5).to(device)\n",
        "y_hat_test = train_and_test(model, train_val_split_group(), num_epochs=1)\n",
        "predictions_file = \"predict_c2_g1_\" + shortuuid.uuid()\n",
        "print('predictions file:', predictions_file)\n",
        "predict_whole_images(y_hat_test, 5, 5, predictions_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nskqko77cNi",
        "colab_type": "text"
      },
      "source": [
        "### Train and Test - All Train Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt3yqV-U7cNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(1024, 128, 0.1).to(device)\n",
        "y_hat_test = train_and_test(model, group_3())\n",
        "predict_whole_images(y_hat_test, 5, 5, 'predictions_c2_g3.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9eyrNE7cNk",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter Optimization\n",
        "The following hyperparameters can be tuned:\n",
        "1. `n1` - Number of neurons in the first classifier dense layer\n",
        "2. `n2` - Number of neurons in the second classifier dense layer\n",
        "3. `d` - Dropout rate after classifier dense layers\n",
        "4. class weights - `[1,1,1,1,1]` (default) or `[1,1,5,5,1]`\n",
        "5. batch normalization - `no` or `yes`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYzqxiwl7cNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_trial(name, model, class_weights=None, num_epochs=40):\n",
        "    y_hat_test = train_and_test(model, train_val_split_group(class_weights), num_epochs)\n",
        "    predictions_file = \"predict_c2_whole_{}_{}.csv\".format(name, shortuuid.uuid())\n",
        "    print('predictions file:', predictions_file)\n",
        "    one_hot_encode_predictions(y_hat_test, predictions_file)\n",
        "\n",
        "    print('Test distribution:')\n",
        "    y_hat_test.bincount()\n",
        "    return y_hat_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ6f-3Os7cNn",
        "colab_type": "text"
      },
      "source": [
        "#### H1: 1024-128-5\n",
        "\n",
        "* DNN Structure: 1024-128-5\n",
        "* Dropout: 0.5\n",
        "* Class weights: [1,1,1,1,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIPG65Ma7cNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4274e2b4-4e87-4416-cb9a-262c89baa6d2"
      },
      "source": [
        "model = get_model(1024, 128, 0.5).to(device)\n",
        "run_trial(\"h1\", model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations...\n",
            "Computing class weights...\n",
            "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
            "Epoch 0/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:50.520122 loss: 1.4049 accuracy: 0.3840\n",
            "Num samples 255\n",
            "val 0:00:10.047908 loss: 1.3047 accuracy: 0.3922\n",
            "Elapsed time: 0:02:00.572431\n",
            "\n",
            "Epoch 1/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.633760 loss: 1.3345 accuracy: 0.4400\n",
            "Num samples 255\n",
            "val 0:00:10.020579 loss: 0.9849 accuracy: 0.5882\n",
            "Elapsed time: 0:01:59.658906\n",
            "\n",
            "Epoch 2/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.625023 loss: 1.1792 accuracy: 0.4735\n",
            "Num samples 255\n",
            "val 0:00:10.145666 loss: 0.9670 accuracy: 0.5804\n",
            "Elapsed time: 0:01:59.771749\n",
            "\n",
            "Epoch 3/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.779085 loss: 1.1220 accuracy: 0.4935\n",
            "Num samples 255\n",
            "val 0:00:09.777529 loss: 0.9349 accuracy: 0.5882\n",
            "Elapsed time: 0:01:59.557664\n",
            "\n",
            "Epoch 4/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.303055 loss: 1.0726 accuracy: 0.5315\n",
            "Num samples 255\n",
            "val 0:00:09.974896 loss: 0.9293 accuracy: 0.6039\n",
            "Elapsed time: 0:01:59.282434\n",
            "\n",
            "Epoch 5/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.012721 loss: 1.0420 accuracy: 0.5400\n",
            "Num samples 255\n",
            "val 0:00:09.746819 loss: 0.9376 accuracy: 0.6157\n",
            "Elapsed time: 0:01:58.763989\n",
            "\n",
            "Epoch 6/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.885884 loss: 0.9882 accuracy: 0.5835\n",
            "Num samples 255\n",
            "val 0:00:10.150345 loss: 0.9367 accuracy: 0.4941\n",
            "Elapsed time: 0:01:59.037840\n",
            "\n",
            "Epoch 7/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.680895 loss: 0.9821 accuracy: 0.5595\n",
            "Num samples 255\n",
            "val 0:00:09.925283 loss: 0.9418 accuracy: 0.6431\n",
            "Elapsed time: 0:01:58.610744\n",
            "\n",
            "Epoch 8/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.494801 loss: 0.9827 accuracy: 0.5720\n",
            "Num samples 255\n",
            "val 0:00:09.913237 loss: 0.8823 accuracy: 0.6275\n",
            "Elapsed time: 0:01:58.409255\n",
            "\n",
            "Epoch 9/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.538517 loss: 0.9506 accuracy: 0.6060\n",
            "Num samples 255\n",
            "val 0:00:09.798272 loss: 0.8510 accuracy: 0.6863\n",
            "Elapsed time: 0:01:58.340980\n",
            "\n",
            "Epoch 10/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.893390 loss: 0.9631 accuracy: 0.5740\n",
            "Num samples 255\n",
            "val 0:00:09.884660 loss: 0.8650 accuracy: 0.6667\n",
            "Elapsed time: 0:01:58.779062\n",
            "\n",
            "Epoch 11/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.396420 loss: 0.9100 accuracy: 0.6015\n",
            "Num samples 255\n",
            "val 0:00:09.996668 loss: 0.9174 accuracy: 0.6863\n",
            "Elapsed time: 0:01:59.395822\n",
            "\n",
            "Epoch 12/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.124297 loss: 0.9167 accuracy: 0.6030\n",
            "Num samples 255\n",
            "val 0:00:09.943646 loss: 0.9080 accuracy: 0.6667\n",
            "Elapsed time: 0:01:58.069262\n",
            "\n",
            "Epoch 13/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.772719 loss: 0.8840 accuracy: 0.6090\n",
            "Num samples 255\n",
            "val 0:00:10.033027 loss: 0.9014 accuracy: 0.6627\n",
            "Elapsed time: 0:01:58.807620\n",
            "\n",
            "Epoch 14/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.396912 loss: 0.8872 accuracy: 0.6205\n",
            "Num samples 255\n",
            "val 0:00:09.939230 loss: 0.8621 accuracy: 0.6667\n",
            "Elapsed time: 0:01:58.337327\n",
            "\n",
            "Epoch 15/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.035527 loss: 0.8983 accuracy: 0.6175\n",
            "Num samples 255\n",
            "val 0:00:09.982219 loss: 0.8806 accuracy: 0.6471\n",
            "Elapsed time: 0:01:58.019036\n",
            "\n",
            "Epoch 16/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.020088 loss: 0.8819 accuracy: 0.6250\n",
            "Num samples 255\n",
            "val 0:00:10.032254 loss: 0.9071 accuracy: 0.6471\n",
            "Elapsed time: 0:01:58.053526\n",
            "\n",
            "Epoch 17/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.691446 loss: 0.9122 accuracy: 0.6155\n",
            "Num samples 255\n",
            "val 0:00:09.964342 loss: 0.8534 accuracy: 0.6706\n",
            "Elapsed time: 0:01:57.656854\n",
            "\n",
            "Epoch 18/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.878375 loss: 0.8669 accuracy: 0.6355\n",
            "Num samples 255\n",
            "val 0:00:09.791620 loss: 0.8137 accuracy: 0.6706\n",
            "Elapsed time: 0:01:58.671416\n",
            "\n",
            "Epoch 19/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.243391 loss: 0.8391 accuracy: 0.6385\n",
            "Num samples 255\n",
            "val 0:00:09.974895 loss: 0.9187 accuracy: 0.6627\n",
            "Elapsed time: 0:01:58.219496\n",
            "\n",
            "Epoch 20/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.292992 loss: 0.8497 accuracy: 0.6320\n",
            "Num samples 255\n",
            "val 0:00:09.723268 loss: 0.7997 accuracy: 0.6824\n",
            "Elapsed time: 0:01:58.017469\n",
            "\n",
            "Epoch 21/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.068440 loss: 0.8639 accuracy: 0.6315\n",
            "Num samples 255\n",
            "val 0:00:09.790542 loss: 0.8123 accuracy: 0.6549\n",
            "Elapsed time: 0:01:57.860197\n",
            "\n",
            "Epoch 22/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.047210 loss: 0.8516 accuracy: 0.6290\n",
            "Num samples 255\n",
            "val 0:00:10.071317 loss: 0.8131 accuracy: 0.6667\n",
            "Elapsed time: 0:01:58.119803\n",
            "\n",
            "Epoch 23/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.187459 loss: 0.8517 accuracy: 0.6495\n",
            "Num samples 255\n",
            "val 0:00:09.853605 loss: 0.7541 accuracy: 0.6902\n",
            "Elapsed time: 0:01:58.045861\n",
            "\n",
            "Epoch 24/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.836559 loss: 0.8306 accuracy: 0.6425\n",
            "Num samples 255\n",
            "val 0:00:09.988725 loss: 0.8854 accuracy: 0.6667\n",
            "Elapsed time: 0:01:57.826519\n",
            "\n",
            "Epoch 25/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.266848 loss: 0.8080 accuracy: 0.6610\n",
            "Num samples 255\n",
            "val 0:00:09.826337 loss: 0.7352 accuracy: 0.6784\n",
            "Elapsed time: 0:01:57.094403\n",
            "\n",
            "Epoch 26/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.228234 loss: 0.8197 accuracy: 0.6545\n",
            "Num samples 255\n",
            "val 0:00:10.079653 loss: 0.7469 accuracy: 0.6902\n",
            "Elapsed time: 0:01:57.309026\n",
            "\n",
            "Epoch 27/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:46.832332 loss: 0.8093 accuracy: 0.6660\n",
            "Num samples 255\n",
            "val 0:00:09.986813 loss: 0.8015 accuracy: 0.6667\n",
            "Elapsed time: 0:01:56.820435\n",
            "\n",
            "Epoch 28/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.313689 loss: 0.8027 accuracy: 0.6645\n",
            "Num samples 255\n",
            "val 0:00:09.943474 loss: 0.7502 accuracy: 0.7020\n",
            "Elapsed time: 0:01:57.266014\n",
            "\n",
            "Epoch 29/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.125547 loss: 0.8092 accuracy: 0.6640\n",
            "Num samples 255\n",
            "val 0:00:09.859051 loss: 0.7615 accuracy: 0.6824\n",
            "Elapsed time: 0:01:57.985908\n",
            "\n",
            "Epoch 30/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.136349 loss: 0.8287 accuracy: 0.6405\n",
            "Num samples 255\n",
            "val 0:00:10.174176 loss: 0.7470 accuracy: 0.6902\n",
            "Elapsed time: 0:01:58.311721\n",
            "\n",
            "Epoch 31/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.008631 loss: 0.7926 accuracy: 0.6535\n",
            "Num samples 255\n",
            "val 0:00:09.788525 loss: 0.7854 accuracy: 0.6902\n",
            "Elapsed time: 0:01:58.798695\n",
            "\n",
            "Epoch 32/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.905530 loss: 0.7808 accuracy: 0.6840\n",
            "Num samples 255\n",
            "val 0:00:09.947724 loss: 0.9536 accuracy: 0.6471\n",
            "Elapsed time: 0:01:57.854988\n",
            "\n",
            "Epoch 33/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.373773 loss: 0.7965 accuracy: 0.6640\n",
            "Num samples 255\n",
            "val 0:00:09.949104 loss: 0.8170 accuracy: 0.6588\n",
            "Elapsed time: 0:01:58.324493\n",
            "\n",
            "Epoch 34/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.819352 loss: 0.7662 accuracy: 0.6820\n",
            "Num samples 255\n",
            "val 0:00:09.865525 loss: 0.7276 accuracy: 0.6902\n",
            "Elapsed time: 0:01:58.686094\n",
            "\n",
            "Epoch 35/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:48.003201 loss: 0.7906 accuracy: 0.6510\n",
            "Num samples 255\n",
            "val 0:00:09.937503 loss: 0.7537 accuracy: 0.6941\n",
            "Elapsed time: 0:01:57.942094\n",
            "\n",
            "Epoch 36/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:47.554956 loss: 0.8001 accuracy: 0.6590\n",
            "Num samples 255\n",
            "val 0:00:09.718123 loss: 0.8015 accuracy: 0.6549\n",
            "Elapsed time: 0:01:57.274287\n",
            "\n",
            "Epoch 37/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.105031 loss: 0.7696 accuracy: 0.6750\n",
            "Num samples 255\n",
            "val 0:00:09.884676 loss: 0.7788 accuracy: 0.6706\n",
            "Elapsed time: 0:01:58.990839\n",
            "\n",
            "Epoch 38/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.913421 loss: 0.7570 accuracy: 0.6925\n",
            "Num samples 255\n",
            "val 0:00:10.009902 loss: 0.7992 accuracy: 0.6549\n",
            "Elapsed time: 0:01:59.924727\n",
            "\n",
            "Epoch 39/39\n",
            "----------\n",
            "Num samples 2000\n",
            "train 0:01:49.233195 loss: 0.7725 accuracy: 0.6780\n",
            "Num samples 255\n",
            "val 0:00:09.958090 loss: 0.7761 accuracy: 0.6588\n",
            "Elapsed time: 0:01:59.192732\n",
            "\n",
            "Training complete in 78m 58s\n",
            "Best acc: 0.701961\n",
            "\n",
            "Metrics\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "predictions file: predict_c2_whole_h1_9EDNcRLZzCydbYBodsqmFC.csv\n",
            "Finished generating predictions to predict_c2_whole_h1_9EDNcRLZzCydbYBodsqmFC.csv\n",
            "Test distribution:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 4, 4, 0, 1, 4, 1, 0, 1, 0, 4, 4, 4, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 4, 0, 1, 0, 4, 1, 4, 1, 1, 4, 4, 0, 1, 0, 1, 4, 1, 0, 0, 4, 1, 1,\n",
              "        1, 1, 0, 0, 1, 4, 4, 4, 0, 4, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 4, 4, 1,\n",
              "        1, 4, 0, 4, 4, 1, 1, 1, 0, 0, 4, 0, 1, 4, 0, 0, 0, 4, 4, 1, 1, 1, 1, 0,\n",
              "        0, 4, 0, 1, 4, 4, 4, 0, 0, 1, 4, 0, 1, 1, 1, 0, 4, 0, 4, 4, 1, 0, 1, 4,\n",
              "        1, 0, 0, 4, 4, 1, 4, 4, 1, 1, 1, 4, 0, 4, 0, 0, 0, 1, 0, 1, 1, 4, 0, 1,\n",
              "        0, 1, 1, 1, 4, 4, 0, 1, 0, 1, 4, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 4, 4,\n",
              "        4, 0, 4, 4, 0, 1, 4, 1, 1, 4, 4, 4, 1, 0, 4, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "        4, 0, 4, 0, 4, 1, 0, 0], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IedWYs7dctv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7d13847-d75e-4257-afd8-983a7e947096"
      },
      "source": [
        "#group = train_val_split_group()\n",
        "#y_hat_test = predict(model, group.test_dataloader)\n",
        "#predictions_file = \"predict_c2_whole_{}_{}.csv\".format(\"h1\", shortuuid.uuid())\n",
        "#print('predictions file:', predictions_file)\n",
        "#one_hot_encode_predictions(y_hat_test, predictions_file)\n",
        "y_hat_test.bincount()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([39, 99,  0,  0, 62], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdBBniN9ffjv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e52cfe70-da78-4afe-8222-6507374c4898"
      },
      "source": [
        "group = train_val_split_group()\n",
        "len(group.test_dataloader)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading annotations...\n",
            "Computing class weights...\n",
            "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFIFN9HC7cNp",
        "colab_type": "text"
      },
      "source": [
        "#### H2: 2048-256-5\n",
        "\n",
        "* DNN Structure: 2048-256-5\n",
        "* Dropout: 0.5\n",
        "* Class weights: [1,1,1,1,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uVz21wq77cNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(2048, 256, 0.5).to(device)\n",
        "run_trial(\"h2\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t42x-Z-77cNr",
        "colab_type": "text"
      },
      "source": [
        "#### H3: 512-64-5\n",
        "\n",
        "* DNN Structure: 512-64-5\n",
        "* Dropout: 0.5\n",
        "* Class weights: [1,1,1,1,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EhTgRkV7cNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(512, 64, 0.5).to(device)\n",
        "run_trial(\"h3\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3co17MA7cNt",
        "colab_type": "text"
      },
      "source": [
        "#### H4: Best from above, dropout 0.25\n",
        "\n",
        "* DNN Structure: \n",
        "* Dropout: 0.25\n",
        "* Class weights: [1,1,1,1,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QO2Xw8T7cNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(n1, n2, 0.25).to(device)\n",
        "run_trial(\"h4\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpyV6kfN7cNv",
        "colab_type": "text"
      },
      "source": [
        "#### H5: Best from above, dropout 0.1\n",
        "\n",
        "* DNN Structure: \n",
        "* Dropout: 0.1\n",
        "* Class weights: [1,1,1,1,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEmmq1lF7cNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(n1, n2, 0.1).to(device)\n",
        "run_trial(\"h5\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0wmNdzd7cNx",
        "colab_type": "text"
      },
      "source": [
        "#### H6: Best from above, skewed class weights\n",
        "\n",
        "* DNN Structure: \n",
        "* Dropout: 0.5\n",
        "* Class weights: [1,1,5,5,1]\n",
        "* Batch normalization: no\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXUYnHqH7cNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(n1, n2, 0.5).to(device)\n",
        "run_trial(\"h6\", model, class_weights=[1., 1., 5., 5., 1.])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPjHhxjQ7cN1",
        "colab_type": "text"
      },
      "source": [
        "#### H7: Best from above, batch normalization\n",
        "\n",
        "* DNN Structure: \n",
        "* Dropout: 0.5\n",
        "* Class weights: \n",
        "* Batch normalization: yes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuxsx-797cN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(n1, n2, 0.5, batch_normalization=True).to(device)\n",
        "run_trial(\"h7\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbvi5JEf7cN3",
        "colab_type": "text"
      },
      "source": [
        "#### Summary: Best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "l-EQAGsU7cN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimal_n1 = 1024\n",
        "optimal_n2 = 128\n",
        "optimal_d = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y21C4M2D7cN4",
        "colab_type": "text"
      },
      "source": [
        "## Train with all C2 data and optimal hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "scrolled": false,
        "id": "cqodK5jX7cN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model(optimal_n1, optimal_n2, optimal_d).to(device)\n",
        "# model.load_state_dict(torch.load('cnn_pytorch_c2.pt'))\n",
        "y_hat_test = train_and_test(model, group_3(), num_epochs=40)\n",
        "predictions_file = \"predict_c2_whole_{}.csv\".format(shortuuid.uuid())\n",
        "print('predictions file:', predictions_file)\n",
        "one_hot_encode_predictions(y_hat_test, predictions_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "__y-plJ97cN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_printoptions(profile=\"full\")\n",
        "print(y_hat_test)\n",
        "torch.set_printoptions(profile=\"default\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GosrUj67cN8",
        "colab_type": "text"
      },
      "source": [
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfi60sat7cN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'cnn_pytorch_c2_whole.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}