{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python==3.4.2.17\n",
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install scikit-learn\n",
    "!pip install scikit-image\n",
    "!pip install scikit-optimize\n",
    "!pip install shortuuid\n",
    "!pip install tensorflow-gpu\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import glob\n",
    "import pathlib\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shortuuid\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Get reproducible results\n",
    "random_state = 46\n",
    "np.random.seed(random_state)\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "\n",
    "def ann_file(data_dir):\n",
    "    return os.path.join(data_dir, \"TrainAnnotations.csv\")\n",
    "\n",
    "\n",
    "TRAIN_DATA_DIR = \"data/TrainData-C1\"\n",
    "TRAIN_DATA_ANN_FILE = ann_file(TRAIN_DATA_DIR)\n",
    "\n",
    "TRAIN_SPLIT_DATA_DIR           = \"data-c1/train/split\"\n",
    "TRAIN_SPLIT_ANN_FILE           = ann_file(TRAIN_SPLIT_DATA_DIR)\n",
    "TRAIN_SPLIT_AUGMENTED_DATA_DIR = \"data-c1/train/augmented\"\n",
    "TRAIN_SPLIT_AUGMENTED_ANN_FILE = ann_file(TRAIN_SPLIT_AUGMENTED_DATA_DIR)\n",
    "TRAIN_SPLIT_PATCHES_DATA_DIR   = \"data-c1/train/patches\"\n",
    "TRAIN_SPLIT_PATCHES_ANN_FILE   = ann_file(TRAIN_SPLIT_PATCHES_DATA_DIR)\n",
    "\n",
    "TRAIN_ALL_AUGMENTED_DATA_DIR   = \"data-c1/train-all/augmented\"\n",
    "TRAIN_ALL_AUGMENTED_ANN_FILE   = ann_file(TRAIN_ALL_AUGMENTED_DATA_DIR)\n",
    "TRAIN_ALL_PATCHES_DATA_DIR     = \"data-c1/train-all/patches\"\n",
    "TRAIN_ALL_PATCHES_ANN_FILE     = ann_file(TRAIN_ALL_PATCHES_DATA_DIR)\n",
    "\n",
    "VAL_SPLIT_DATA_DIR         = \"data-c1/val/split\"\n",
    "VAL_SPLIT_ANN_FILE         = ann_file(VAL_SPLIT_DATA_DIR)\n",
    "VAL_SPLIT_PATCHES_DATA_DIR = \"data-c1/val/patches\"\n",
    "VAL_SPLIT_PATCHES_ANN_FILE = ann_file(VAL_SPLIT_PATCHES_DATA_DIR)\n",
    "\n",
    "TEST_DATA_DIR         = \"data/TestData/\"\n",
    "TEST_PATCHES_DATA_DIR = \"data/test/patches\"\n",
    "\n",
    "# Keras ImageDataGenerator expects that files are in a subdirectory\n",
    "TEST_PATCHES_GEN_DATA_DIR = os.path.join(TEST_PATCHES_DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU configuration\n",
    "If you have a GPU, enable experimental memory growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "Generate random, stratified 80/20 split for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(TRAIN_SPLIT_DATA_DIR) or os.path.exists(VAL_SPLIT_DATA_DIR)):\n",
    "    print(\"Data directories for splits already exist. Skipping\")\n",
    "else:\n",
    "    # Generate 80/20 split\n",
    "\n",
    "    print(\"Reading {} annotations...\".format(TRAIN_DATA_ANN_FILE))\n",
    "    ann_df = pd.read_csv(TRAIN_DATA_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "\n",
    "    print(\"Splitting data into training and validation sets...\")\n",
    "    train_df, val_df = train_test_split(ann_df,\n",
    "                                        train_size=0.80,\n",
    "                                        random_state=138,\n",
    "                                        shuffle=True,\n",
    "                                        stratify=ann_df[['annotation']].to_numpy(dtype=np.int32).flatten())\n",
    "\n",
    "    os.makedirs(TRAIN_SPLIT_DATA_DIR)\n",
    "    os.makedirs(VAL_SPLIT_DATA_DIR)\n",
    "    \n",
    "    print(\"Copying files for training split...\")\n",
    "    for _, row in train_df.iterrows():\n",
    "        filename = row['file_name']\n",
    "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
    "        dest = os.path.join(TRAIN_SPLIT_DATA_DIR, filename)\n",
    "        shutil.copyfile(src, dest)\n",
    "        \n",
    "    print(\"Generating training split annotations...\")\n",
    "    train_df.sort_values('file_name').to_csv(TRAIN_SPLIT_ANN_FILE, index=False)\n",
    "        \n",
    "    print(\"Copying files for validation split...\")\n",
    "    for _, row in val_df.iterrows():\n",
    "        filename = row['file_name']\n",
    "        src = os.path.join(TRAIN_DATA_DIR, filename)\n",
    "        dest = os.path.join(VAL_SPLIT_DATA_DIR, filename)\n",
    "        shutil.copyfile(src, dest)\n",
    "        \n",
    "    print(\"Generating validation split annotations...\")\n",
    "    val_df.sort_values('file_name').to_csv(VAL_SPLIT_ANN_FILE, index=False)\n",
    "        \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment data\n",
    "Because the training dataset is unbalanced, augment the training data set by generating\n",
    "new images for the lower numbered samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DESIRED_CLASS_SAMPLE_COUNT = 400\n",
    "RANDOM_STATE = 13\n",
    "\n",
    "IMG_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp')\n",
    "PATCH_ROWS = 5\n",
    "PATCH_COLUMNS = 5\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.endswith(IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def augment_data(src_dir, src_ann_file, dest_dir, dest_ann_file, class_sample_count=500):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "    ann_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'}) \n",
    "    new_samples = {}\n",
    "    \n",
    "    for i in range(5):\n",
    "        class_df = ann_df.query(\"annotation == '{}'\".format(i))\n",
    "        num_class_samples = class_df.shape[0]\n",
    "        num_to_create = class_sample_count - num_class_samples\n",
    "            \n",
    "        print(\"Creating {} images for class {}\".format(num_to_create, i))\n",
    "        samples = class_df.sample(n=num_to_create, replace=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "        for idx, row in samples.iterrows():\n",
    "            new_filename = row['file_name'].split('.')[0] + \"_\" + shortuuid.uuid() + \".png\"\n",
    "    \n",
    "            # Apply transformations to each randomly selected sample\n",
    "            img = Image.open(src_dir + \"/\" + row['file_name'])\n",
    "            image_transforms = transforms.Compose([\n",
    "                #transforms.RandomAffine(degrees=20, translate=(0.2, 0.2)),\n",
    "                #transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                #transforms.RandomResizedCrop((480, 640), scale=(1.0, 1.2)),\n",
    "                \n",
    "                transforms.RandomRotation((90,90), expand=True),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.RandomHorizontalFlip()\n",
    "            ])\n",
    "            transformed_img = image_transforms(img)\n",
    "            transformed_img.save(os.path.join(dest_dir, new_filename))\n",
    "    \n",
    "            new_samples[new_filename] = row['annotation']\n",
    "    \n",
    "    # Add to new dataframe\n",
    "    balanced_df = pd.read_csv(src_ann_file, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    balanced_df = balanced_df.append(pd.DataFrame.from_records([(k, v) for k, v in new_samples.items()],\n",
    "                                                 columns=['file_name', 'annotation']))\n",
    "    \n",
    "    # Write new annotations\n",
    "    balanced_df.sort_values('file_name').to_csv(dest_ann_file, index=False)\n",
    "    \n",
    "    # Copy images from training data split\n",
    "    for file in glob.glob(src_dir + \"/*\"):\n",
    "        if is_image_file(file):\n",
    "            shutil.copy(file, os.path.join(dest_dir, os.path.basename(file)))\n",
    "\n",
    "\n",
    "def generate_image_patches(img, rows, cols):\n",
    "    \"\"\"\n",
    "    Generates a list of in-memory image overlapping patches\n",
    "    \n",
    "    Args:\n",
    "        rows - number of rows of patchs to cover the height of the image\n",
    "        cols - number of colums of patches to cover the width of the image\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    sizeX = img.shape[1]\n",
    "    sizeY = img.shape[0]\n",
    "    \n",
    "    patch_sizeX = 224\n",
    "    patch_sizeY = 224\n",
    "    patch_relative_centerX = 112\n",
    "    patch_relative_centerY = 112\n",
    "\n",
    "    for i in range(0,rows):\n",
    "        for j in range(0, cols):\n",
    "            center = (patch_relative_centerX + (sizeX - patch_sizeX)/(rows - 1)*i, \n",
    "                      patch_relative_centerY + (sizeY - patch_sizeY)/(cols - 1)*j)\n",
    "            patches.append(cv2.getRectSubPix(img, (patch_sizeX, patch_sizeY), center))\n",
    "            \n",
    "    return patches\n",
    "\n",
    "\n",
    "def generate_patch_files(in_dir, out_dir, rows, cols):\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    images = [f for f in os.listdir(in_dir) if os.path.isfile(os.path.join(in_dir, f)) and is_image_file(f)]   \n",
    "    for im in images:\n",
    "        img = cv2.imread(os.path.join(in_dir, im))\n",
    "        patches = generate_image_patches(img, rows, cols)\n",
    "        \n",
    "        for i in range(0,rows):\n",
    "            for j in range(0, cols):\n",
    "                patch = patches[i*rows + j]\n",
    "                patch_name = im.split('.')[0] + '_' + str(i) + '_' + str(j) + '.png'\n",
    "                cv2.imwrite(out_dir + '/' + patch_name, patch)\n",
    "\n",
    "\n",
    "def generate_patch_annotations_df(df, rows, cols):\n",
    "    patches_ann = {}\n",
    "    \n",
    "    for ind in df.index: \n",
    "        file_name = df['file_name'][ind]\n",
    "        annotation = df['annotation'][ind]\n",
    "        \n",
    "        for i in range(0, rows):\n",
    "            for j in range(0, cols):\n",
    "                patch_name = file_name.split('.')[0] + '_' + str(i) + '_' + str(j) + '.png'\n",
    "                patches_ann[patch_name] = annotation\n",
    "    \n",
    "    return pd.DataFrame.from_records([(k, v) for k, v in patches_ann.items()], \n",
    "                                     columns=['file_name', 'annotation'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run data augmentation\n",
    "\n",
    "Perform the data augmentation on the training data set split to balance the class samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_SPLIT_AUGMENTED_DATA_DIR):\n",
    "    print(\"Augmented SPLIT training data already exists. Skipping.\")\n",
    "else:\n",
    "    print(\"Balancing class samples for SPLIT training data...\")\n",
    "    augment_data(TRAIN_SPLIT_DATA_DIR,\n",
    "                 TRAIN_SPLIT_ANN_FILE,\n",
    "                 TRAIN_SPLIT_AUGMENTED_DATA_DIR,\n",
    "                 TRAIN_SPLIT_AUGMENTED_ANN_FILE,\n",
    "                 class_sample_count=400)    \n",
    "    print(\"Done.\")\n",
    "\n",
    "if os.path.exists(TRAIN_ALL_AUGMENTED_DATA_DIR):\n",
    "    print(\"Augmented ALL training data already exists. Skipping.\")\n",
    "else:\n",
    "    print(\"Balancing class samples for ALL training data...\")\n",
    "    augment_data(TRAIN_DATA_DIR,\n",
    "                 TRAIN_DATA_ANN_FILE,\n",
    "                 TRAIN_ALL_AUGMENTED_DATA_DIR,\n",
    "                 TRAIN_ALL_AUGMENTED_ANN_FILE,\n",
    "                 class_sample_count=500)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT train patches\n",
    "if os.path.exists(TRAIN_SPLIT_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TRAIN_SPLIT_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating SPLIT training data patches...\")\n",
    "    generate_patch_files(TRAIN_SPLIT_AUGMENTED_DATA_DIR, TRAIN_SPLIT_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating SPLIT training patch data annotations...\")\n",
    "    image_df = pd.read_csv(TRAIN_SPLIT_AUGMENTED_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(TRAIN_SPLIT_PATCHES_ANN_FILE, index=False)\n",
    "    \n",
    "# SPLIT val patches\n",
    "if os.path.exists(VAL_SPLIT_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(VAL_SPLIT_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating SPLIT validation data patches...\")\n",
    "    generate_patch_files(VAL_SPLIT_DATA_DIR, VAL_SPLIT_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating SPLIT validation patch data annotations...\")\n",
    "    image_df = pd.read_csv(VAL_SPLIT_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(VAL_SPLIT_PATCHES_ANN_FILE, index=False)\n",
    "\n",
    "# test patches\n",
    "if os.path.exists(TEST_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TEST_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating test data patches...\")\n",
    "    generate_patch_files(TEST_DATA_DIR, TEST_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    \n",
    "# ALL train patches\n",
    "if os.path.exists(TRAIN_ALL_PATCHES_DATA_DIR):\n",
    "    print(\"{} exists. Skipping.\".format(TRAIN_ALL_PATCHES_DATA_DIR))\n",
    "else:\n",
    "    print(\"Generating ALL train data patches...\")\n",
    "    generate_patch_files(TRAIN_ALL_AUGMENTED_DATA_DIR, TRAIN_ALL_PATCHES_DATA_DIR, PATCH_ROWS, PATCH_COLUMNS)\n",
    "\n",
    "    print(\"Generating ALL training patch data annotations...\")\n",
    "    image_df = pd.read_csv(TRAIN_ALL_AUGMENTED_ANN_FILE)\n",
    "    patch_annotations_df = generate_patch_annotations_df(image_df, PATCH_ROWS, PATCH_COLUMNS)\n",
    "    patch_annotations_df.sort_values('file_name').to_csv(TRAIN_ALL_PATCHES_ANN_FILE, index=False)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoybeanDataGroup():\n",
    "    def __init__(self, class_weights, \n",
    "                 train_generator,\n",
    "                 train_prediction_generator,\n",
    "                 val_generator=None,\n",
    "                 val_prediction_generator=None,\n",
    "                 test_generator=None,\n",
    "                 train_patch_ann_df=None,\n",
    "                 val_patch_ann_df=None,\n",
    "                 train_whole_image_ann_df=None,\n",
    "                 val_whole_image_ann_df=None):\n",
    "        self.class_weights = class_weights\n",
    "        self.train_generator = train_generator\n",
    "        self.train_prediction_generator = train_prediction_generator\n",
    "        self.val_generator = val_generator\n",
    "        self.val_prediction_generator = val_prediction_generator\n",
    "        self.test_generator = test_generator\n",
    "        self.train_patch_ann_df = train_patch_ann_df\n",
    "        self.val_patch_ann_df = val_patch_ann_df\n",
    "        self.train_whole_image_ann_df = train_whole_image_ann_df\n",
    "        self.val_whole_image_ann_df = val_whole_image_ann_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split_group(class_weights=None):\n",
    "    \n",
    "    train_whole_image_ann_df = pd.read_csv(TRAIN_SPLIT_AUGMENTED_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    val_whole_image_ann_df   = pd.read_csv(VAL_SPLIT_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    \n",
    "    print(\"Reading annotations...\")\n",
    "    train_ann_df = pd.read_csv(TRAIN_SPLIT_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    val_ann_df   = pd.read_csv(VAL_SPLIT_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    \n",
    "    if class_weights is None:\n",
    "        print(\"Computing class weights...\")\n",
    "        class_weights = compute_class_weights(train_ann_df, 'annotation')\n",
    "        print(class_weights)\n",
    "    else:\n",
    "        print(\"Using class weights:\", class_weights)\n",
    "        \n",
    "        \n",
    "    data_gen_args = dict(\n",
    "        preprocessing_function=tf.keras.applications.vgg16.preprocess_input,\n",
    "        #rotation_range=10,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        #horizontal_flip=True\n",
    "    )\n",
    "    train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    val_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "\n",
    "    print(\"Defining train data generator...\")\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=train_ann_df,\n",
    "            directory=TRAIN_SPLIT_PATCHES_DATA_DIR,\n",
    "            x_col=\"file_name\",\n",
    "            y_col=\"annotation\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='sparse',\n",
    "            target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    train_prediction_generator = train_datagen.flow_from_dataframe(\n",
    "            dataframe=train_ann_df,\n",
    "            directory=TRAIN_SPLIT_PATCHES_DATA_DIR,\n",
    "            x_col=\"file_name\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            shuffle=False,\n",
    "            target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    print(\"Defining validation data generator...\")\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=val_ann_df,\n",
    "            directory=VAL_SPLIT_PATCHES_DATA_DIR,\n",
    "            x_col=\"file_name\",\n",
    "            y_col=\"annotation\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='sparse',\n",
    "            target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    val_prediction_generator = val_datagen.flow_from_dataframe(\n",
    "            dataframe=val_ann_df,\n",
    "            directory=VAL_SPLIT_PATCHES_DATA_DIR,\n",
    "            x_col=\"file_name\",\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode=None,\n",
    "            shuffle=False,\n",
    "            target_size=(224,224)\n",
    "    )\n",
    "        \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=TEST_PATCHES_DATA_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    return SoybeanDataGroup(class_weights, \n",
    "                            train_generator,\n",
    "                            train_prediction_generator,\n",
    "                            val_generator, \n",
    "                            val_prediction_generator,\n",
    "                            test_generator,\n",
    "                            train_ann_df,\n",
    "                            val_ann_df,\n",
    "                            train_whole_image_ann_df, \n",
    "                            val_whole_image_ann_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def all_train_data_group(class_weights=None):\n",
    "    \n",
    "    train_whole_image_ann_df = pd.read_csv(TRAIN_DATA_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})    \n",
    "    \n",
    "    print(\"Reading annotations...\")\n",
    "    ann_df = pd.read_csv(TRAIN_DATA_PATCHES_ANN_FILE, dtype={'file_name': 'object', 'annotation': 'category'})\n",
    "    \n",
    "    if class_weights is None:\n",
    "        print(\"Computing class weights...\")\n",
    "        class_weights = compute_class_weights(ann_df, 'annotation')\n",
    "        print(class_weights)\n",
    "    else:\n",
    "        print(\"Using class weights:\", class_weights)\n",
    "        \n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "    print(\"Defining train data generator...\")\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=ann_df,\n",
    "        directory=TRAIN_DATA_PATCHES_DIR,\n",
    "        x_col=\"file_name\",\n",
    "        y_col=\"annotation\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='sparse',\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "    \n",
    "    train_prediction_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_ann_df,\n",
    "        directory=TRAIN_DATA_PATCHES_DIR,\n",
    "        x_col=\"file_name\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "   \n",
    "        \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        directory=TEST_DATA_PATCHES_DIR,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "        target_size=(224,224)\n",
    "    )  \n",
    "    \n",
    "    \n",
    "    return SoybeanDataGroup(class_weights, \n",
    "                            train_generator, \n",
    "                            None, \n",
    "                            test_generator,\n",
    "                            ann_df,\n",
    "                            None,\n",
    "                            train_whole_image_ann_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This model is based on the VGG16 network with custom classifier layers \n",
    "with the feature layers initialized with weights based on the ImageNet data. \n",
    "\n",
    "The number of neurons and dropout rates in the classifier layers are parameterized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_model(n1, n2, dropout):\n",
    "    vgg_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\n",
    "    vgg_model.trainable = False\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        vgg_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(n1, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(n2, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(5)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "For training and validation, this trains a model across a configured number of epochs and outputs the training and validation loss and accuracy for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def compute_class_weights(df, y_col):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping class labels to 'balanced' weights based on the\n",
    "    frequency of the weights across the labels in the specified dataframe\n",
    "    \"\"\"\n",
    "    y = df[[y_col]].to_numpy().flatten()\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "    return {label: weight for label, weight in enumerate(weights)}\n",
    "    \n",
    "\n",
    "def train(run_id, model, group, num_epochs):     \n",
    "    model.summary()\n",
    "\n",
    "    print('Fitting model...')\n",
    "    \n",
    "    print('group.train_patch_ann_df.shape[0]=', group.train_patch_ann_df.shape[0])\n",
    "    print('int(group.train_patch_ann_df.shape[0] / BATCH_SIZE)', int(group.train_patch_ann_df.shape[0] / BATCH_SIZE))\n",
    "\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(group.train_generator, \n",
    "                        steps_per_epoch=int(group.train_patch_ann_df.shape[0] / BATCH_SIZE), \n",
    "                        epochs=num_epochs,  \n",
    "                        class_weight=group.class_weights,\n",
    "                        validation_data=group.val_generator,\n",
    "                        validation_steps=int(group.val_patch_ann_df.shape[0] / BATCH_SIZE),\n",
    "                        verbose=1,\n",
    "                        callbacks=[es])\n",
    "\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "def get_all_labels(ann_df):\n",
    "    return ann_df['annotation'].to_numpy(dtype=int)\n",
    "\n",
    "\n",
    "def get_all_whole_image_filenames(whole_image_ann_df):\n",
    "    return whole_image_ann_df['file_name'].to_numpy()\n",
    "    \n",
    "\n",
    "def get_all_whole_image_labels(ann_df):\n",
    "    return get_all_labels(ann_df)\n",
    "\n",
    "\n",
    "def get_all_whole_image_predictions(patch_preds):\n",
    "    patch_pred_groups = np.split(patch_preds, int(len(patch_preds)/(PATCH_ROWS * PATCH_COLUMNS)))\n",
    "    image_preds = np.array(list(map(lambda x: stats.mode(x).mode[0], patch_pred_groups)))\n",
    "    return image_preds\n",
    "\n",
    "\n",
    "def plot_metrics(run_id, output_dir, model, history, group):\n",
    "    \n",
    "    print()\n",
    "    print('Metrics')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    plt.plot(history.history['loss'], label='Training loss')\n",
    "    plt.plot(history.history['val_loss'], label = 'Validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'Validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # Training confusion matrix\n",
    "    train_patch_labels = get_all_labels(group.train_patch_ann_df)\n",
    "    train_patch_predictions = predict(model, group.train_prediction_generator)\n",
    "    \n",
    "    print(\"Training Confusion Matrix of Patches\")\n",
    "    print(\"-\" * 30)\n",
    "    print_confusion_matrix(train_patch_labels, train_patch_predictions)\n",
    "    \n",
    "    # Generate prediction label results file\n",
    "    write_patch_predictions(run_id, 'train', output_dir, group.train_patch_ann_df, train_patch_predictions)\n",
    "    \n",
    "    \n",
    "    print(\"Training Confusion Matrix of Whole Images\")\n",
    "    print(\"-\" * 30)\n",
    "    train_whole_image_filenames = get_all_whole_image_filenames(group.train_whole_image_ann_df)\n",
    "    train_whole_image_labels = get_all_whole_image_labels(group.train_whole_image_ann_df)\n",
    "    train_whole_image_predictions = get_all_whole_image_predictions(train_patch_predictions)\n",
    "    print_confusion_matrix(train_whole_image_labels, train_whole_image_predictions)\n",
    "    \n",
    "    write_whole_image_predictions(run_id, 'train', output_dir, \n",
    "                                  train_whole_image_filenames, \n",
    "                                  train_whole_image_labels, \n",
    "                                  train_whole_image_predictions)\n",
    "    \n",
    "    # Validation confusion matrix\n",
    "    if group.val_generator is not None:\n",
    "        val_patch_labels = get_all_labels(group.val_patch_ann_df)\n",
    "        val_patch_predictions = predict(model, group.val_prediction_generator)\n",
    "        \n",
    "        print(\"Validation Confusion Matrix of Patches\")\n",
    "        print(\"-\" * 30)\n",
    "        print_confusion_matrix(val_patch_labels, val_patch_predictions)\n",
    "      \n",
    "        print(\"Validation Confusion Matrix of Whole Images\")\n",
    "        print(\"-\" * 30)\n",
    "        val_whole_image_filenames = get_all_whole_image_filenames(group.val_whole_image_ann_df)\n",
    "        val_whole_image_labels = get_all_whole_image_labels(group.val_whole_image_ann_df)\n",
    "        val_whole_image_predictions = get_all_whole_image_predictions(val_patch_predictions)\n",
    "        print_confusion_matrix(val_whole_image_labels, val_whole_image_predictions)\n",
    "        \n",
    "        # Generate prediction label results file\n",
    "        write_patch_predictions(run_id, 'val', output_dir, group.val_patch_ann_df, val_patch_predictions)\n",
    "        \n",
    "        write_whole_image_predictions(run_id, 'val', output_dir, \n",
    "                                  val_whole_image_filenames, \n",
    "                                  val_whole_image_labels, \n",
    "                                  val_whole_image_predictions)\n",
    "    \n",
    "\n",
    "\n",
    "def train_and_test(run_id, model, group, num_epochs, output_dir):    \n",
    "    model_trained, history = train(run_id, model, group, num_epochs)\n",
    "    \n",
    "    # Save weights\n",
    "    model_trained.save_weights(os.path.join(output_dir, \"{}_weights.h5\".format(run_id)))\n",
    "    \n",
    "    # Plot history metrics\n",
    "    plot_metrics(run_id, output_dir, model_trained, history, group)\n",
    "    \n",
    "    # Classify test data\n",
    "    return predict(model_trained, group.test_generator)\n",
    "\n",
    "\n",
    "def predict(model, data_generator):\n",
    "    y_hat_logits = model.predict(data_generator)\n",
    "    y_hat = tf.map_fn(lambda x: tf.argmax(x), y_hat_logits, dtype=tf.int64).numpy()\n",
    "    print('prediction => ', np.bincount(y_hat))\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "\n",
    "def predict_whole_images(patch_predictions, rows, columns, csvfile):\n",
    "    y_hat_test = patch_predictions\n",
    "    y_hat_patch_groups = np.split(y_hat_test, int(len(y_hat_test)/(rows * columns)))\n",
    "    y_hat_whole_images = list(map(lambda x: stats.mode(x).mode[0], y_hat_patch_groups))\n",
    "\n",
    "    print(\"Distribution\")\n",
    "    print('-' * 8)\n",
    "    for k, v in sorted(Counter(y_hat_whole_images).items()): \n",
    "        print(str(k) + ': '+ str(v))    \n",
    "\n",
    "    one_hots = [np.zeros((5,1)) for pred in y_hat_whole_images]\n",
    "    for i in range(len(one_hots)):\n",
    "        pred = y_hat_whole_images[i]  # the index of the one-hot encoding\n",
    "        one_hots[i][pred] = 1\n",
    "    with open(csvfile, 'w') as predictions_file:\n",
    "        writer = csv.writer(predictions_file)\n",
    "        for pred in one_hots:\n",
    "            pred = np.array(pred, dtype=int)\n",
    "            writer.writerow(pred.T.tolist()[0])\n",
    "    print('Finished generating predictions to', csvfile)\n",
    "\n",
    "\n",
    "def print_confusion_matrix(y, y_hat):\n",
    "    labels = [0, 1, 2, 3, 4]\n",
    "    matrix = confusion_matrix(y, y_hat)\n",
    "    df = pd.DataFrame(matrix, index=labels, columns=labels)\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def write_patch_predictions(run_id, phase, output_dir, patch_ann_df, patch_predictions):\n",
    "    df = pd.DataFrame(columns=['file_name', 'annotation', 'prediction'])\n",
    "    i = 0\n",
    "    for idx, row in patch_ann_df.iterrows():\n",
    "        file_name, label = row\n",
    "        df = df.append({'file_name': file_name, \n",
    "                        'annotation': label, \n",
    "                        'prediction': patch_predictions[i]}, ignore_index=True)\n",
    "        i += 1\n",
    "\n",
    "    df.to_csv(os.path.join(output_dir, \"{}_{}_patch_predictions.csv\".format(run_id, phase)), index=False)\n",
    "    \n",
    "\n",
    "def write_whole_image_predictions(run_id, phase, output_dir, filenames, labels, predictions):\n",
    "    print('filenames:', len(filenames))\n",
    "    print('labels:', len(labels))\n",
    "    print('predictions:', len(predictions))\n",
    "    \n",
    "    df = pd.DataFrame(columns=['file_name', 'annotation', 'prediction'])\n",
    "    for i in range(len(filenames)):\n",
    "        df = df.append({'file_name': filenames[i], \n",
    "                        'annotation': labels[i], \n",
    "                        'prediction': predictions[i]}, ignore_index=True)\n",
    "        \n",
    "    df.to_csv(os.path.join(output_dir, \"{}_{}_whole_image_predictions.csv\".format(run_id, phase)), index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "The following hyperparameters can be tuned:\n",
    "1. `n1` - Number of neurons in the first classifier dense layer\n",
    "2. `n2` - Number of neurons in the second classifier dense layer\n",
    "3. `d` - Dropout rate after classifier dense layers\n",
    "4. class weights - `[1,1,1,1,1]` (default) or `[1,1,5,5,1]`\n",
    "5. batch normalization - `no` or `yes`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(name, model, class_weights=None, num_epochs=80):\n",
    "    run_id = shortuuid.uuid()\n",
    "    \n",
    "    # output directory\n",
    "    output_dir = os.path.join(\"output_tf\", run_id)\n",
    "    os.makedirs(output_dir)\n",
    "    print(\"Output generated to:\", output_dir)\n",
    "    \n",
    "    \n",
    "    y_hat_test = train_and_test(run_id, model, train_val_split_group(class_weights), num_epochs, output_dir)\n",
    "    predictions_file = os.path.join(output_dir, \"{}_predict_c2_{}_test.csv\".format(run_id, name))\n",
    "    print('predictions file:', predictions_file)\n",
    "    predict_whole_images(y_hat_test, PATCH_ROWS, PATCH_COLUMNS, predictions_file)\n",
    "    return y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H1: 1024-128-5\n",
    "\n",
    "* DNN Structure: 1024-128-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.5)\n",
    "run_trial(\"h1\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H2: 2048-256-5\n",
    "\n",
    "* DNN Structure: 2048-256-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model(2048, 256, 0.5)\n",
    "run_trial(\"h2\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H3: 512-64-5\n",
    "\n",
    "* DNN Structure: 512-64-5\n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(512, 64, 0.5)\n",
    "run_trial(\"h3\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H4: Best from above, dropout 0.25\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.25\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.25)\n",
    "run_trial(\"h4\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H5: Best from above, dropout 0.1\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.1\n",
    "* Class weights: [1,1,1,1,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.1)\n",
    "run_trial(\"h5\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H6: Best from above, skewed class weights\n",
    "\n",
    "* DNN Structure: \n",
    "* Dropout: 0.5\n",
    "* Class weights: [1,1,5,5,1]\n",
    "* Batch normalization: no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(1024, 128, 0.5)\n",
    "run_trial(\"h6\", model, class_weights=[1., 1., 2., 2., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary: Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "optimal_n1 = 1024\n",
    "optimal_n2 = 128\n",
    "optimal_d = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with all C2 data and optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(optimal_n1, optimal_n2, optimal_d)\n",
    "y_hat_test = train_and_test(model, group_3(), num_epochs=80)\n",
    "\n",
    "predictions_file = \"predict_c2_{}.csv\".format(shortuuid.uuid())\n",
    "print('predictions file:', predictions_file)\n",
    "\n",
    "predict_whole_images(y_hat_test, PATCH_ROWS, PATCH_COLUMNS, predictions_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
